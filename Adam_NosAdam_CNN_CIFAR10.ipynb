{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "MJUkPE3B4oYT",
      "metadata": {
        "id": "MJUkPE3B4oYT"
      },
      "source": [
        "## Tuning Adam and NosAdam on CNN with CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e359ffb-71a2-43db-87a3-4de42e63aa55",
      "metadata": {
        "id": "9e359ffb-71a2-43db-87a3-4de42e63aa55"
      },
      "source": [
        "# 1.Imports & environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a167aec-3ddd-4067-8b5f-77af4fe2854f",
      "metadata": {
        "id": "2a167aec-3ddd-4067-8b5f-77af4fe2854f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gzip\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle\n",
        "# os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "# Setup predictable randomization\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Setup CUda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c42f77e-92d5-4cb3-9099-b699d7c7858d",
      "metadata": {
        "id": "8c42f77e-92d5-4cb3-9099-b699d7c7858d"
      },
      "source": [
        "# 2. Loading and preparing the data\n",
        "Here, we use CIFAR10 dataset containing 60k $32\\times32$ colored images from 10 different classes (labels): plane, car, bird, cat, deer, dog, frog, horse, ship, and truck."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3668867e-acbe-4676-84dc-1911b88c0729",
      "metadata": {
        "id": "3668867e-acbe-4676-84dc-1911b88c0729"
      },
      "source": [
        "### 2.1. Definition of methods to extract data and labels\n",
        "source: https://stackoverflow.com/questions/37512290/reading-cifar10-dataset-in-batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vSEmcUPnR-et",
      "metadata": {
        "id": "vSEmcUPnR-et"
      },
      "outputs": [],
      "source": [
        "def load_CIFAR_batch(filename):\n",
        "    \"\"\" load single batch of cifar \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='latin1')\n",
        "        X = datadict['data']\n",
        "        Y = datadict['labels']\n",
        "        X = X.reshape(10000,3072)\n",
        "        Y = np.array(Y)\n",
        "        return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "    \"\"\" load all of cifar \"\"\"\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for b in range(1,6):\n",
        "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "        X, Y = load_CIFAR_batch(f)\n",
        "        xs.append(X)\n",
        "        ys.append(Y)\n",
        "    Xtr = np.concatenate(xs)\n",
        "    Ytr = np.concatenate(ys)\n",
        "    del X, Y\n",
        "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, Yte\n",
        "\n",
        "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = 'drive/MyDrive/cifar-10-batches-py/'\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a048581f-bdb6-4a22-9b0c-9f371c1303b3",
      "metadata": {
        "id": "a048581f-bdb6-4a22-9b0c-9f371c1303b3"
      },
      "source": [
        "### 2.2. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yU4LqChpSiBq",
      "metadata": {
        "id": "yU4LqChpSiBq"
      },
      "outputs": [],
      "source": [
        "train_images, train_labels, test_images, test_labels = get_CIFAR10_data(num_training=50000, num_test=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff8b6f8-0472-4936-a88d-cde07e2359b4",
      "metadata": {
        "id": "eff8b6f8-0472-4936-a88d-cde07e2359b4"
      },
      "source": [
        "### 2.3. Convert data from numpy arrays to torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b5bfe7-685e-4adc-8a48-fc1a25a39381",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3b5bfe7-685e-4adc-8a48-fc1a25a39381",
        "outputId": "2b943bb5-ee56-442d-f0ce-bbff73c4401c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features: torch.Size([50000, 3072]) \n",
            "Testing features: torch.Size([10000, 3072])\n",
            "Training labels: torch.Size([50000]) \n",
            "Testing labels: torch.Size([10000])\n"
          ]
        }
      ],
      "source": [
        "features_train=torch.from_numpy(train_images).to(device)\n",
        "features_test=torch.from_numpy(test_images).to(device)\n",
        "print('Training features:', features_train.shape, '\\n'\n",
        "'Testing features:', features_test.shape)\n",
        "\n",
        "labels_train=torch.from_numpy(train_labels).to(device)\n",
        "labels_test=torch.from_numpy(test_labels).to(device)\n",
        "print('Training labels:', labels_train.shape, '\\n'\n",
        "'Testing labels:', labels_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072269a3-e3f6-470c-8ca9-58a0555d9851",
      "metadata": {
        "id": "072269a3-e3f6-470c-8ca9-58a0555d9851"
      },
      "source": [
        "### 2.4. Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d24f2cbd-0279-44d6-89d2-1dca355248df",
      "metadata": {
        "id": "d24f2cbd-0279-44d6-89d2-1dca355248df"
      },
      "outputs": [],
      "source": [
        "mean, std = features_train.float().mean(), features_train.float().std()\n",
        "\n",
        "features_train = features_train.float().sub_(mean).div_(std)\n",
        "features_test = features_test.float().sub_(mean).div_(std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gO2vsS-k6GY9",
      "metadata": {
        "id": "gO2vsS-k6GY9"
      },
      "outputs": [],
      "source": [
        "#reshape to make the 1st channel be a batch size\n",
        "\n",
        "features_train = features_train.reshape(-1, 3, 32, 32)\n",
        "features_test = features_test.reshape(-1, 3, 32, 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc94097-21c0-4308-ba10-af4dc6d04f30",
      "metadata": {
        "id": "bdc94097-21c0-4308-ba10-af4dc6d04f30"
      },
      "source": [
        "# 3. Setting up networks and evaluation methods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g3hZg487lszk",
      "metadata": {
        "id": "g3hZg487lszk"
      },
      "source": [
        "### 3.1. Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yUu42pH8l5md",
      "metadata": {
        "id": "yUu42pH8l5md"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "   def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=5, stride=1, padding='same')\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=5, stride=1, padding='same')\n",
        "        self.fc1 = nn.Linear(64*8*8, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "   def forward(self, input:torch.Tensor) -> torch.Tensor:\n",
        "        pool1 = torch.max_pool2d(F.relu(self.conv1(input)), kernel_size=2, stride=2)\n",
        "        pool2 = torch.max_pool2d(F.relu(self.conv2(pool1)), kernel_size=2, stride=2)\n",
        "        res = pool2.reshape(-1, 64*8*8)\n",
        "        hidden = F.relu(self.fc1(res))\n",
        "        output = self.fc2(hidden)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e119d2d9-562a-4bdf-8ce7-eea9d59272fa",
      "metadata": {
        "id": "e119d2d9-562a-4bdf-8ce7-eea9d59272fa"
      },
      "source": [
        "### 3.2. Implementation of method for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e5ca3dd-313e-4c15-99da-10937d42595c",
      "metadata": {
        "id": "8e5ca3dd-313e-4c15-99da-10937d42595c"
      },
      "outputs": [],
      "source": [
        "def run_nn(x_train, y_train, x_test, y_test, model, optimizer, criterion, num_epoch, size_minibatch):\n",
        "\n",
        "    loss_train_ret = 0\n",
        "    loss_test_ret = 0\n",
        "    loss_train = 0\n",
        "            \n",
        "    for epoch in range(num_epoch):\n",
        "        for b in range(0, x_train.size(0), size_minibatch):\n",
        "            y = model(x_train[b:b+size_minibatch])\n",
        "            loss_train = criterion(y, y_train[b:b+size_minibatch])\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch == num_epoch - 1:\n",
        "\n",
        "            y_test_obt = model(x_test)\n",
        "            loss_test = criterion(y_test_obt, y_test)\n",
        "            \n",
        "            loss_train_ret = loss_train\n",
        "            loss_test_ret = loss_test\n",
        "            \n",
        "            print('Final, Train Loss: %.4f, Test Loss: %.4f' %(loss_train, loss_test))\n",
        "\n",
        "    return loss_train_ret, loss_test_ret"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93565277-6e32-47ca-8c17-55098b57d7bb",
      "metadata": {
        "id": "93565277-6e32-47ca-8c17-55098b57d7bb"
      },
      "source": [
        "# 4. Metrics of our tuning protocol\n",
        "At this stage, we want to select the hyperparameter search space for each optimizer. This way, we can first tune the hyperparameters of each optimizer separately and then select the trial that achieved lowest final validation error.\n",
        "We then comapre the optimizers' performance by looking at the validation and test errors as suggested in the paper \"On empirical comparisons of optimizers for deep learning\".\n",
        "\n",
        "No regularization is used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a304d9-db74-4bc5-a12c-b97b971097bd",
      "metadata": {
        "id": "92a304d9-db74-4bc5-a12c-b97b971097bd"
      },
      "source": [
        "### 4.1. Tuning Adam for the CNN on CIFAR10\n",
        "The hyperparameters we are tuning are alpha_0/epsilon, 1 - beta_1, 1 - beta_2, epsilon.\n",
        "The final search spaces are suggested based on the experience of the writers of the same paper, \"On empirical comparisons of optimizers for deep learning\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465c3fd8-c425-4ce5-991a-0ad3cd2ba426",
      "metadata": {
        "id": "465c3fd8-c425-4ce5-991a-0ad3cd2ba426"
      },
      "source": [
        "##### Set up model for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FfnUAu5xzl5Z",
      "metadata": {
        "id": "FfnUAu5xzl5Z"
      },
      "outputs": [],
      "source": [
        "# Model fixed parameters\n",
        "model = CNN()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device) # good loss function for classification tasks\n",
        "num_epoch = 50\n",
        "size_minibatch = 128\n",
        "\n",
        "x_train = features_train\n",
        "y_train = labels_train\n",
        "x_test = features_test\n",
        "y_test = labels_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t1eNEdgdzl5a",
      "metadata": {
        "id": "t1eNEdgdzl5a",
        "tags": []
      },
      "source": [
        "##### Tune to find best parameter\n",
        "We perform trials until we have K of them, then we pick the best based on our statistic of interest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BcWL5tIe0yBY",
      "metadata": {
        "id": "BcWL5tIe0yBY"
      },
      "source": [
        "##### Set up parameters and search space for the final trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2LHRX7mT0yBY",
      "metadata": {
        "id": "2LHRX7mT0yBY"
      },
      "outputs": [],
      "source": [
        "N = 200\n",
        "K = 50 # Number of trials being kept for the statistic\n",
        "\n",
        "# Final search spaces for parameters\n",
        "alpha_0 = np.linspace(10**(-1), 10, N)\n",
        "beta_1 = np.linspace(10**(-3), 1, N)\n",
        "beta_2 = np.linspace(10**(-4), 1, N)\n",
        "eps = np.linspace(10**(-6), 10**(-2), N)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VSruqZFS0yBZ",
      "metadata": {
        "id": "VSruqZFS0yBZ"
      },
      "source": [
        "Perform search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mormnp9dw7Z9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mormnp9dw7Z9",
        "outputId": "5f2ceb58-f818-4b46-eec0-448f1796b4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final, Train Loss: 2.3004, Test Loss: 2.3059\n",
            "Final, Train Loss: 1.4072, Test Loss: 1.2655\n",
            "Final, Train Loss: 2.3045, Test Loss: 2.3033\n",
            "Final, Train Loss: 2.3032, Test Loss: 2.3037\n",
            "Final, Train Loss: 2.3067, Test Loss: 2.3047\n",
            "Final, Train Loss: 0.4793, Test Loss: 13.0637\n",
            "Final, Train Loss: 2.2789, Test Loss: 2.2826\n",
            "Final, Train Loss: 0.1766, Test Loss: 15.7397\n",
            "Final, Train Loss: 2.3004, Test Loss: 2.3057\n",
            "Final, Train Loss: 2.2980, Test Loss: 2.3079\n",
            "Final, Train Loss: 2.2971, Test Loss: 2.3105\n",
            "Final, Train Loss: 2.3031, Test Loss: 2.3035\n",
            "Final, Train Loss: 2.2965, Test Loss: 2.3112\n",
            "Final, Train Loss: 2.3080, Test Loss: 2.3035\n",
            "Final, Train Loss: 2.3047, Test Loss: 2.3028\n",
            "Final, Train Loss: 0.1361, Test Loss: 15.1877\n",
            "Final, Train Loss: 1.0629, Test Loss: 1.0116\n",
            "Final, Train Loss: 2.3057, Test Loss: 2.3034\n",
            "Final, Train Loss: 2.3130, Test Loss: 2.3067\n",
            "Final, Train Loss: 2.3031, Test Loss: 2.3059\n",
            "Final, Train Loss: 2.2964, Test Loss: 2.3106\n",
            "Final, Train Loss: 2.3022, Test Loss: 2.3042\n",
            "Final, Train Loss: 0.0007, Test Loss: 2.6003\n",
            "Final, Train Loss: 2.3071, Test Loss: 2.3152\n",
            "Final, Train Loss: 2.2984, Test Loss: 2.3078\n",
            "Final, Train Loss: 2.2970, Test Loss: 2.3094\n",
            "Final, Train Loss: 2.3024, Test Loss: 2.3042\n",
            "Final, Train Loss: 0.0000, Test Loss: 2.3519\n",
            "Final, Train Loss: 2.3014, Test Loss: 2.3050\n",
            "Final, Train Loss: 0.0000, Test Loss: 2.8548\n",
            "Final, Train Loss: 2.3012, Test Loss: 2.3051\n",
            "Final, Train Loss: 2.3032, Test Loss: 2.3040\n",
            "Final, Train Loss: 2.3061, Test Loss: 2.3045\n",
            "Final, Train Loss: 0.5977, Test Loss: 18.8617\n",
            "Final, Train Loss: 1.9564, Test Loss: 2.7150\n",
            "Final, Train Loss: 2.2994, Test Loss: 2.3066\n",
            "Final, Train Loss: 2.3058, Test Loss: 2.3045\n",
            "Final, Train Loss: 2.3074, Test Loss: 2.3047\n",
            "Final, Train Loss: 2.2998, Test Loss: 2.3067\n",
            "Final, Train Loss: 2.3048, Test Loss: 2.3038\n",
            "Final, Train Loss: 0.0001, Test Loss: 5.3056\n",
            "Final, Train Loss: 2.3030, Test Loss: 2.3048\n",
            "Final, Train Loss: 0.1858, Test Loss: 16.9449\n",
            "Final, Train Loss: 2.3038, Test Loss: 2.3039\n",
            "Final, Train Loss: 1.8812, Test Loss: 21.7538\n",
            "Final, Train Loss: 2.3056, Test Loss: 2.3032\n",
            "Final, Train Loss: 2.1854, Test Loss: 18.7348\n",
            "Final, Train Loss: 1.1482, Test Loss: 3.8926\n",
            "Final, Train Loss: 2.3077, Test Loss: 2.3046\n",
            "Final, Train Loss: 0.4653, Test Loss: 9.1459\n"
          ]
        }
      ],
      "source": [
        "nb_hyperamaters_to_tune = 4\n",
        "nb_exported_statistics  = 2\n",
        "\n",
        "lowest_test_error = [sys.maxsize] * (nb_hyperamaters_to_tune + nb_exported_statistics)\n",
        "\n",
        "\n",
        "for _ in range(K):\n",
        "    # Pick random values from the intervals given for the different parameters\n",
        "    alpha_0_pick  = float(np.random.choice(alpha_0, 1)) # np.random.choice samples uniformely with replacement\n",
        "    beta_1_pick   = float(-np.random.choice(beta_1, 1) + 1)\n",
        "    beta_2_pick   = float(-np.random.choice(beta_2, 1) + 1)\n",
        "    eps_pick      = float(np.random.choice(eps, 1))\n",
        "    learning_rate = alpha_0_pick * eps_pick\n",
        "    \n",
        "    # Build optimizer from parameters\n",
        "    model=CNN()\n",
        "    model=model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1_pick, beta_2_pick), eps=eps_pick)\n",
        "    \n",
        "    # Run\n",
        "    train_error, test_error = run_nn(x_train,y_train, x_test, y_test, model, optimizer, criterion, num_epoch, size_minibatch)\n",
        "    \n",
        "    # Concatenate hyperparameters with results\n",
        "    vector = [beta_1_pick, beta_2_pick, eps_pick, learning_rate, train_error, test_error]\n",
        "    \n",
        "    # Check wether we have the smallest test error and store parameters in case we find it\n",
        "    if test_error < lowest_test_error[len(lowest_test_error) - 1]:\n",
        "        lowest_test_error = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52xLPeV8w3ZX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52xLPeV8w3ZX",
        "outputId": "c150d107-02a4-4492-90bf-2c0c3e74c1f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beta 1: 0.31\n",
            "Beta 2: 0.82\n",
            "Epsilon: 1.00e-06\n",
            "Learning rate: 9.50e-06\n",
            "Train error: 1.062902\n",
            "Test error: 1.0116\n"
          ]
        }
      ],
      "source": [
        "# Print best parameters\n",
        "\n",
        "print('Beta 1: %.2f' % lowest_test_error[0])\n",
        "print('Beta 2: %.2f' % lowest_test_error[1])\n",
        "print('Epsilon: %.2e' % lowest_test_error[2])\n",
        "print('Learning rate: %.2e' % lowest_test_error[3])\n",
        "print('Train error: %.6f' % lowest_test_error[4])\n",
        "print('Test error: %.4f' % lowest_test_error[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4QMdt95e81Uz",
      "metadata": {
        "id": "4QMdt95e81Uz"
      },
      "source": [
        "Run the model again with the best parameters to plot the convergence later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65UAk5e2OvQP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65UAk5e2OvQP",
        "outputId": "6e0a55dc-de8a-4003-c862-53fa88d1a904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final, Train Loss: 1.0535, Test Loss: 1.0287\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "model = model.to(device)\n",
        "learning_rate = lowest_test_error[3]\n",
        "beta_1 = lowest_test_error[0]\n",
        "beta_2 = lowest_test_error[1]\n",
        "eps = lowest_test_error[2]\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1, beta_2), eps=eps)\n",
        "    \n",
        "loss_all_train_adam, loss_all_test_adam = [], []\n",
        "            \n",
        "for epoch in range(num_epoch):\n",
        "     for b in range(0, x_train.size(0), size_minibatch):\n",
        "            y = model(x_train[b:b+size_minibatch])\n",
        "            loss_train = criterion(y, y_train[b:b+size_minibatch])\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "      \n",
        "     loss_train = loss_train.to('cpu').detach().numpy()\n",
        "     loss_all_train_adam.append(loss_train)\n",
        "\n",
        "     y_test_obt = model(x_test)\n",
        "     loss_test = criterion(y_test_obt, y_test)\n",
        "     loss_test = loss_test.to('cpu').detach().numpy()\n",
        "     loss_all_test_adam.append(loss_test)\n",
        "     if epoch == num_epoch - 1 :\n",
        "        print('Final, Train Loss: %.4f, Test Loss: %.4f' %(loss_train, loss_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vlCpwVK0F0Zi",
      "metadata": {
        "id": "vlCpwVK0F0Zi"
      },
      "source": [
        "### 4.2. Tuning NosAdam for the CNN on CIFAR10\n",
        "The hyperparameters we are tuning are alpha_0/epsilon, 1 - beta_1, 1 - beta_2, epsilon.\n",
        "The final search spaces are suggested based on the experience of the writers of the same paper, \"On empirical comparisons of optimizers for deep learning\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ve5Lz-7UF9QY",
      "metadata": {
        "id": "Ve5Lz-7UF9QY"
      },
      "source": [
        "Loading the NosAdam optimizer, source: https://github.com/andrehuang/NostalgicAdam-NosAdam "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77tZeD0VFAnp",
      "metadata": {
        "id": "77tZeD0VFAnp"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class NosAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
        "                 weight_decay=0, gamma=0, lr_decay=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        if not 0.0 <= gamma:\n",
        "            raise ValueError(\"Invalid gamma value: {}\".format(gamma))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, gamma=gamma, lr_decay=lr_decay)\n",
        "        super(NosAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(NosAdam, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('lr_decay', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                # amsgrad = group['amsgrad']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                    state['B_old'] = 0\n",
        "                    state['B_new'] = 1\n",
        "                    # if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        # state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                # if amsgrad:\n",
        "                #     max_exp_avg_sq = state['max_exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "                beta2 = state['B_old']/state['B_new']\n",
        "                gamma = group['gamma']\n",
        "                # pnorm = group['pnorm']\n",
        "                lr_decay = group['lr_decay']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                step = state['step']\n",
        "                state['B_old'] += math.pow(step, -gamma)\n",
        "                state['B_new'] += math.pow(step+1, -gamma)\n",
        "\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    grad = grad.add(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                # if pnorm == 2:\n",
        "                #     exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                # elif pnorm ==3:\n",
        "                #     # exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, np.multiply(grad, grad))\n",
        "                #     exp_avg_sq = beta2*exp_avg_sq + (1 - beta2) * np.power(grad, 3)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                # if amsgrad:\n",
        "                #     # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                #     torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
        "                #     # Use the max. for normalizing running avg. of gradient\n",
        "                #     denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                # else:\n",
        "                # if pnorm ==2:\n",
        "                #     denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                # elif pnorm==3: # pnorm = 3\n",
        "                #     denom = np.cbrt(exp_avg_sq) + group['eps']\n",
        "\n",
        "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                # AdaStab no longer needs bias correction for v_t\n",
        "                # bias_correction2 = 1 - beta2 ** state['step']\n",
        "                step_size = group['lr'] / bias_correction1\n",
        "                if lr_decay:\n",
        "                    step_size = step_size/math.sqrt(state['step'])\n",
        "\n",
        "\n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def denominator(self):\n",
        "        denom = np.array([0])\n",
        "        denom_sum = 0\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "\n",
        "                state = self.state[p]\n",
        "                exp_avg_sq = state[\"exp_avg_sq\"]\n",
        "\n",
        "                exp_avg_sq = exp_avg_sq.numpy()\n",
        "                exp_avg_sq = np.reshape(exp_avg_sq, -1)\n",
        "                denom = np.concatenate((denom, exp_avg_sq))\n",
        "                denom_sum += torch.sum(exp_avg_sq)\n",
        "        return denom, denom_sum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G3j0s3vpGLXd",
      "metadata": {
        "id": "G3j0s3vpGLXd"
      },
      "source": [
        "Perform search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mNgMPRPzFMAe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNgMPRPzFMAe",
        "outputId": "0e0e7cdb-695e-46d1-92a4-df7e99313de0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:86: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final, Train Loss: 0.0010, Test Loss: 2.7916\n",
            "Final, Train Loss: 2.2992, Test Loss: 2.3065\n",
            "Final, Train Loss: 1.1551, Test Loss: 1.0601\n",
            "Final, Train Loss: 0.0904, Test Loss: 4.5935\n",
            "Final, Train Loss: 2.3020, Test Loss: 2.3044\n",
            "Final, Train Loss: 2.3035, Test Loss: 2.3031\n",
            "Final, Train Loss: 2.3028, Test Loss: 2.3036\n",
            "Final, Train Loss: 2.3009, Test Loss: 2.3050\n",
            "Final, Train Loss: 2.3011, Test Loss: 2.3050\n",
            "Final, Train Loss: 1.5986, Test Loss: 1.8827\n",
            "Final, Train Loss: 0.1845, Test Loss: 4.8542\n",
            "Final, Train Loss: 0.1216, Test Loss: 6.3692\n",
            "Final, Train Loss: 2.2981, Test Loss: 2.3077\n",
            "Final, Train Loss: 0.4838, Test Loss: 1.9783\n",
            "Final, Train Loss: 1.6897, Test Loss: 2.6228\n",
            "Final, Train Loss: 2.2986, Test Loss: 2.3071\n",
            "Final, Train Loss: 0.0091, Test Loss: 7.2132\n",
            "Final, Train Loss: 2.3060, Test Loss: 2.3040\n",
            "Final, Train Loss: 2.3029, Test Loss: 2.3049\n",
            "Final, Train Loss: 1.8847, Test Loss: 2.2957\n",
            "Final, Train Loss: 2.2980, Test Loss: 2.3078\n",
            "Final, Train Loss: 0.0096, Test Loss: 3.2084\n",
            "Final, Train Loss: 2.3032, Test Loss: 2.3040\n",
            "Final, Train Loss: 2.2748, Test Loss: 2.3030\n",
            "Final, Train Loss: 2.2975, Test Loss: 2.3087\n",
            "Final, Train Loss: 0.0245, Test Loss: 2.7307\n",
            "Final, Train Loss: 0.0878, Test Loss: 7.2560\n",
            "Final, Train Loss: 2.3033, Test Loss: 2.3040\n",
            "Final, Train Loss: 2.3020, Test Loss: 2.3043\n",
            "Final, Train Loss: 0.0002, Test Loss: 4.5172\n",
            "Final, Train Loss: 2.3106, Test Loss: 2.3046\n",
            "Final, Train Loss: 2.2998, Test Loss: 2.3060\n",
            "Final, Train Loss: 2.3034, Test Loss: 2.3033\n",
            "Final, Train Loss: 2.3006, Test Loss: 2.3057\n",
            "Final, Train Loss: 2.3028, Test Loss: 2.3040\n",
            "Final, Train Loss: 2.3041, Test Loss: 2.3030\n",
            "Final, Train Loss: 0.1234, Test Loss: 8.0585\n",
            "Final, Train Loss: 2.2974, Test Loss: 2.3089\n",
            "Final, Train Loss: 2.3008, Test Loss: 2.3051\n",
            "Final, Train Loss: 2.3040, Test Loss: 2.3036\n",
            "Final, Train Loss: 2.2985, Test Loss: 2.3072\n",
            "Final, Train Loss: 2.2976, Test Loss: 2.3089\n",
            "Final, Train Loss: 2.3036, Test Loss: 2.3029\n",
            "Final, Train Loss: 0.0282, Test Loss: 2.9664\n",
            "Final, Train Loss: 0.0060, Test Loss: 1.6143\n",
            "Final, Train Loss: 1.8887, Test Loss: 1.8789\n",
            "Final, Train Loss: 2.2996, Test Loss: 2.3061\n",
            "Final, Train Loss: 1.8008, Test Loss: 2.1015\n",
            "Final, Train Loss: 2.2997, Test Loss: 2.3060\n",
            "Final, Train Loss: 2.3033, Test Loss: 2.3031\n"
          ]
        }
      ],
      "source": [
        "nb_hyperamaters_to_tune = 4\n",
        "nb_exported_statistics  = 2\n",
        "\n",
        "lowest_test_error = [sys.maxsize] * (nb_hyperamaters_to_tune + nb_exported_statistics)\n",
        "\n",
        "\n",
        "for _ in range(K):\n",
        "    # Pick random values from the intervals given for the different parameters\n",
        "    alpha_0_pick  = float(np.random.choice(alpha_0, 1)) # np.random.choice samples uniformely with replacement\n",
        "    beta_1_pick   = float(-np.random.choice(beta_1, 1) + 1)\n",
        "    beta_2_pick   = float(-np.random.choice(beta_2, 1) + 1)\n",
        "    eps_pick      = float(np.random.choice(eps, 1))\n",
        "    learning_rate = alpha_0_pick * eps_pick\n",
        "    \n",
        "    # Build optimizer from parameters\n",
        "    model=CNN()\n",
        "    model=model.to(device)\n",
        "    optimizer = NosAdam(model.parameters(), lr=learning_rate, betas=(beta_1_pick, beta_2_pick), eps=eps_pick)\n",
        "    \n",
        "    # Run\n",
        "    train_error, test_error = run_nn(x_train,y_train, x_test, y_test, model, optimizer, criterion, num_epoch, size_minibatch)\n",
        "    \n",
        "    # Concatenate hyperparameters with results\n",
        "    vector = [beta_1_pick, beta_2_pick, eps_pick, learning_rate, train_error.item(), test_error.item()]\n",
        "    \n",
        "    # Check wether we have the smallest test error and store parameters in case we find it\n",
        "    if test_error < lowest_test_error[len(lowest_test_error) - 1]:\n",
        "        lowest_test_error = vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YgxzL66GGPHf",
      "metadata": {
        "id": "YgxzL66GGPHf"
      },
      "source": [
        "Print the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vn4XbYpZFlVx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn4XbYpZFlVx",
        "outputId": "64cd75c6-4d24-4303-f050-da9c44341fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beta 1: 0.9588\n",
            "Beta 2: 0.6331\n",
            "Epsilon: 1.00e-06\n",
            "Learning rate: 5.72e-06\n",
            "Train error: 1.155129\n",
            "Test error: 1.0601\n"
          ]
        }
      ],
      "source": [
        "# Print best parameters\n",
        "\n",
        "print('Beta 1: %.4f' % lowest_test_error[0])\n",
        "print('Beta 2: %.4f' % lowest_test_error[1])\n",
        "print('Epsilon: %.2e' % lowest_test_error[2])\n",
        "print('Learning rate: %.2e' % lowest_test_error[3])\n",
        "print('Train error: %.6f' % lowest_test_error[4])\n",
        "print('Test error: %.4f' % lowest_test_error[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0vVBX9cRGSAs",
      "metadata": {
        "id": "0vVBX9cRGSAs"
      },
      "source": [
        "Run the model again to plot the convergence later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O4QG1QQlFmUy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4QG1QQlFmUy",
        "outputId": "2a8125f9-cf5a-4565-e534-701531efe056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final, Train Loss: 1.1263, Test Loss: 1.0516\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "model = model.to(device)\n",
        "learning_rate = lowest_test_error[3]\n",
        "beta_1 = lowest_test_error[0]\n",
        "beta_2 = lowest_test_error[1]\n",
        "eps = lowest_test_error[2]\n",
        "optimizer = NosAdam(model.parameters(), lr=learning_rate, betas=(beta_1, beta_2), eps=eps)\n",
        "    \n",
        "loss_all_train_nosadam, loss_all_test_nosadam = [], []\n",
        "            \n",
        "for epoch in range(num_epoch):\n",
        "     for b in range(0, x_train.size(0), size_minibatch):\n",
        "            y = model(x_train[b:b+size_minibatch])\n",
        "            loss_train = criterion(y, y_train[b:b+size_minibatch])\n",
        "        \n",
        "            optimizer.zero_grad()\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "      \n",
        "     loss_train = loss_train.to('cpu').detach().numpy()\n",
        "     loss_all_train_nosadam.append(loss_train)\n",
        "\n",
        "     y_test_obt = model(x_test)\n",
        "     loss_test = criterion(y_test_obt, y_test)\n",
        "     loss_test = loss_test.to('cpu').detach().numpy()\n",
        "     loss_all_test_nosadam.append(loss_test)\n",
        "     if epoch == num_epoch - 1 :\n",
        "        print('Final, Train Loss: %.4f, Test Loss: %.4f' %(loss_train, loss_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6uP9nBFu9D7D",
      "metadata": {
        "id": "6uP9nBFu9D7D"
      },
      "source": [
        "Plots of models' convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZRJn7SEN9Hd-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "ZRJn7SEN9Hd-",
        "outputId": "d725a838-5049-49e6-e064-8fe0c4574524"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1zV1f/A8dddcNl7bxURRXCbOVNTM5w4v64sR6VpZTlKbaiZ5cjRdG/NLcOdew8cKCgaKuAAZO91f3/c5KcyBLwM4Twfjx6P+MxzuB/f93DO+byPRKVSqRAEQRCqPGlFF0AQBEEoHyLgC4IgVBMi4AuCIFQTIuALgiBUEyLgC4IgVBMi4AuCIFQT8oouQFEuXrxY0UUQBEF4LTVu3Djftkod8KHgQhdHcHAw7u7uGi5N5SfqXb2Ielcvxa13YY1l0aUjCIJQTYiALwiCUE2IgC8IglBNiIAvCIJQTYiALwiCUE2IgC8IglBNlOm0zJ9++omLFy+SnZ3N6NGj6dSpU96+U6dOMX/+fGQyGW3atGHMmDFlWRRBEIRqr8xa+GfOnCE0NJTNmzezbNkyfvjhh+f2z5w5k8WLF7Nx40ZOnjzJ7du3NXbvaSensTF8o8auJwhCwX788UeGDBlCly5daNu2LUOGDGHs2LHFOvezzz4jPT39pcdFRETQu3fvVy1qkTIyMmjSpAmrVq0qcH9KSgrt27cv0zKUhzJr4Tdt2hRPT08ADA0NSUtLIycnB5lMRnh4OEZGRtjY2ADQtm1bTp8+Ta1atTRy74zsDE7FnOJb1bdIJaLXShDKyuTJkwHYvn07oaGhTJo0qdjnLliwoKyKVWJHjhzB3NycgIAA3nvvvYouTpkps4Avk8nQ1dUFYOvWrbRp0waZTAZAdHQ0pqameceampoSHh5e4HWCg4NLfG8XiQt7svaw9+JeXPRcSlH611d6enqpfmevO1HvivXgwQOePHmSV5aFCxcil8tJSkpi3LhxzJ8/n/T0dDIyMhg5ciS1a9dm5MiRLFq0iL/++gtTU1Pu3LlDTEwMn332GTVr1sy79uPHj/PVMz09nT179vDXX38hkUjQ0dFh/PjxSKVSfv75Z7KyssjOzmbUqFFYW1vn2/bs9QE2bNiAj48PK1eu5MiRI1hZWZGamsqcOXPIzMykbt26ZGZmEhwczNGjR/H390cqleLg4MCYMWM4dOgQ169fJzExkfDwcAYNGsTx48cJDw/n888/p3bt2hr5Pb/q513mqRUOHjzI1q1bWbFiRanOL83r0xbOFvwW9hsPtB/Q1b1rqe77uhKvnFcvz9Z728UI/r5QcMOptPo1ccCnsX2xypGSkpJXFmNjY8zNzfniiy8ICwtj+PDhdOzYkdOnT7NhwwZ69OiBlpYWbm5uGBsbY2hoyObNm9m4cSNXrlzB29s779oGBgYolcrnPt/g4GA2btzIt99+i5eXF8uXL+fMmTPUqVOHmjVr8sMPPxAeHk5YWBixsbH5tj17reTkZG7evMmff/5JbGwsN2/epF27dqxfv54GDRrw1VdfERAQwJkzZ3B3d+fq1ausX78eQ0NDBg0ahFQqxdbWlpMnT7Jhwwa2bNnC2rVr2blzJ9u3bycoKIgePXpo5POo1KkVjh8/zh9//MHSpUsxMDDI225paUlMTEzez48fP8bS0lJj9zXXMcdF14UTkSc0dk1BEErmaZeuubk5+/btY+DAgcydO5f4+Ph8xzZp0gQAa2trkpOTi3X9O3fu4OXlBUDz5s25ceMGDRo04PLly0yfPp179+7Rpk2bArc9a9++fbRq1QqlUom3tzd+fn5512/YsCEAzZo1yzveyMiIjz/+mMGDB3Pnzp28+nh4eCCRSLCwsMDNzQ2ZTIa5uXmx61MeyqyFn5SUxE8//cSqVaswNjZ+bp+9vT3JyclERERgbW3N4cOHmTt3rkbv72Xkhd8jP5IykzDQMnj5CYLwmvNpbF+s1nh5USgUAKxevRorKyt+/vlnrl27xk8//ZTv2KfdvQAqlarE98rKykIqlWJpacmuXbs4e/YsGzdu5PLly4wdO7bAbU/5+flx//79vFb43bt3uX37NiqVCqlU3SbOzc0FIDMzk++//55du3ZhYWHB6NGj864jl8sL/P/S1KeslFnADwgIIC4ujk8//TRvW/PmzXFzc+Ptt9/m22+/ZcKECQB07doVFxfN9rU3MGrAzoc7OffwHB2cOmj02oIgFF9cXBxubm6Auos3KytLI9d1dXUlMDCQhg0bcv78eTw8PDh16hRZWVm0bduWWrVq8e233xa47ano6Ghu377N4cOH84L0kiVL8PPzw8XFhaCgIDp37szZs2cB9WwdmUyGhYUFDx8+JCgoSGP1KQ9lFvD79+9P//79C93ftGlTNm/eXFa3p7Z+bfQUepx4cEIEfEGoQD169GDSpEns3buXQYMG4efnx7Zt20p0jbCwMIYMGZL3c58+fZg6dSrfffcdEokEIyMjZs+eTXx8PF9++SXLli1DIpEwbtw4rK2t8217KiAgAG9v7+da5L169eL9999ny5YtjBkzhmHDhuWlaTcxMaFly5b4+PhQp04dRowYwezZsxk2bNgr/pbKh0RVmf7eeMHFixdfKR/+n4/+5MaTG+zz2YdEItFw6SonMXhZvYh6Vy8lGbQtKHZW6UnqLe1a8jDlIWEJYRVdFEEQhApXJQP+w4Q0EtNzaGnbEkDM1hEEQaCKBvwJf19hwalobPVtqWFUg5MPTlZ0kQRBECpclQz4ta0MCHyQRkZ2Di3tWnLh0QXSstMquliCIAgVqkoG/Nau5mTkqLh4N45Wtq3IzM3kwqMLFV0sQRCEClUlA/4bNcyQS+FYaAyNrRujlClFt44gCNVelQz4etpy3C2UHLsVjbZMmybWTTgZKQK+IGjaq6RHBggJCSEsLP8suvbt25OSkqLJoubzwQcf8PHHHxe6v3fv3kRERJRpGcpbmSdPqyiN7XRYdSmO6KQMWtm14sdzPxKeFI6DgUNFF00QqoxXSY8McODAATw8PDT+pv3LPHnyhDt37pCenk5SUtJzub6qsiob8BvZ6rLqUhwnb8fQsoZ6euapyFP0r1P427+CILy6nJwcpk2bRnh4ONnZ2YwbN44WLVqwc+dO1q1bh0KhoE6dOgwYMIBNmzZhamqKmZlZXrK1wiQlJTF58mQSExNJSkpi1qxZ1KtXj5kzZxIUFEROTg4DBw6kd+/eBW57VkBAAG+99RaJiYns378fHx8fQL0wU2BgIC4uLnkpE0JCQvjuu++Qy+VIpVIWLlxIcnIyEydOxNHRkcDAQAYOHMjNmze5cuUKgwYNYtCgQWXzy31FVTbg1zTVwkRXwbHQaHo08MJO344TD06IgC9UXZc3QuA6zV6z4WBoMLBEp/j6+mJhYcEPP/xAbGwsw4YNw9fXl+XLl/PXX39hY2PDtm3bcHJyonXr1nTu3PmlwR7USdi8vLwYNWoUvr6+zJ49myVLlnDkyJG8HD07duwgPj4+37YX+fn58eWXX5KUlMS6devw8fHh9u3bXLp0ia1bt/L48WPefvttQP3XwLRp06hbty4LFy7E19eXt956i+DgYH799VcSEhLw9vbm0KFDZGRk8Mknn4iAX96kEgmtXC04HqpOw9zKrhW77+wmKycLhUxRwaUThKorMDCQixcvcunSJUC9fGBmZibe3t6MGTOG7t274+3tjVKpLNF1g4KC+OijjwCoVasW9+7dw9jYGGdnZz766CO6dOlCz5490dLSyrftWeHh4Tx+/JjGjRuTnZ3N1KlTiY2N5fbt23h5eSGVSrGxscHBQd39a2Zmxty5c0lPTycqKopu3boB4OjoiImJCVpaWpiammJlZUVKSgpJSUmv+issM1U24IN6eqbvlQeEPEqipW1LNt/cTGBUIM1smr38ZEF43TQYWOLWeFlQKBR8+OGHzy1iAjB69Gi6devGvn37GDZsGOvWleyvEYlE8lyq4acpi5ctW8b169fx8/Nj165drFixosBtT/n5+ZGRkZH3RZCdnc2ePXswNTXNS4f87PVnzZrFyJEjadOmDcuXLyc1NRV4PqXzs8nXKrMqOUvnqTauFgAcD42mmU0z5FI5Jx6INAuCUJa8vLw4dOgQoO4OmT9/Prm5uSxYsAALCwuGDx9OgwYNePDgARKJhJycnGJdt379+nlpim/evImrqysRERGsWbOGevXqMWnSJOLj4wvc9ix/f39WrVrFrl272LVrF0uWLMHf3x8XFxeuX7+OSqUiMjKSyMhIAOLj43F0dCQzM5OjR4++VumQX/R6fC2VkrWRktpW+hwPjWFUm5o0smzEsfBjfNbos2qTPVMQyts777zDmTNnGDBgADk5OYwdOxapVIqenh79+/fHwMAABwcH3N3dadKkCTNnzkRPT48WLVo8d52RI0fmtaK9vb0ZOnQoX331FUOHDiU5OZk5c+ZgaWlJYGAgAQEBKBQKfHx8Ctz2VEhISN7Sik81adKEJ0+eYGRkRO3atenfvz/Ozs7UqVMHgMGDBzNmzBgcHBwYMmQI33//PV27vqZLp6oqsQsXLpT63Bs3bqhUKpXqe9/rKtevA1RpmdmqzSGbVR6rPFRXo65qqoiVztN6Vzei3tWLqHfRCoudVbpLB9T9+JnZuZwLi6WrS1d05DpsDd1a0cUSBEEod1U+4Dd3MUNLLuXYrWj0tfTp6tKVPWF7SMqsvCPpgiAIZaFKBvysx48hUR3QdbRkNHM2zZue2bd2X9Ky0wj4N6AiiygIglDuqmTAf/DlRPjj97yfW7uac/NxEo8T06lrVhd3U3e23NpSqVaTFwRBKGtVMuArbG3h+o28gN46b3pmDBKJhD61+3Az7iZBMUEVWUxBEIRyVSUDvo6XJyQmkvXfPNo61gaY62tz7FY0gBi8FQShWqqSAV/5X16OtCtXAJBKJbR2NefE7Rhyc1Vi8FYQNORV0iN/9tlnpKenv/S4iIiIfMnPNOns2bM0bNiQ6OjovG2LFy/Oe8mrpCpz2uWqGfBr1wYtLdKvXs3b1qa2ObEpmdx4mAiIwVtB0ITJkyezdu1aRo0aRdeuXVm7di1Lliwp1rkLFiwocT6dsmJvb1/schfladrlS5cuVcqcOlXyTVuJQgE1apB25f8Dfsta5gAcC43Gw87oucHbfm79xJu3gqBBkydPRqFQEB8fz+zZs5kwYQKpqamkp6czbdo0PD09ad++Pb6+vsyYMQNLS0uuX7/OgwcPmDt3LvXq1XvpPW7evMn333+f9xbvjz/+iEwm49NPPyUzM5PMzEymT5+Oo6Njvm0vXr9Tp06cPHmSsLCwfLn5f/rpJy5dukROTg6DBg2iZ8+e+VI9f/PNN0DZp11u1KjRK30uVTLgA1DblfS9+1BlZiLR0sLSQIm7jSHHbkXzcbtaeYO3M87MICgmiPoW9Su6xILwSnbf2c2O0PypgF9FL9dedK/ZvVTnGhkZMWPGDMLCwujbty8dO3bk9OnTLF26lMWLFz93bGZmJsuXL2fjxo3s3LmzWAF/1qxZTJw4ES8vL5YvX86aNWuoU6cOVlZW/PDDD4SHhxMWFkZkZGS+bQX57LPPmD9//nNlO3/+PKGhoWzatInU1FS6d+9Ox44d86V6Tk9PR6lUlnna5VcN+FWySweA2rVRZWaSfvNW3qb2dSw4FxZLVJK631AM3gpC2Xma497c3Jx9+/YxcOBA5s6dmy+ZGajz2QBYW1uTnJxcrOvfuXMHLy8vAJo3b86NGzdo0KABly9fZvr06dy7d482bdoUuK0gzZs3JzMzk8uXL+dtCwoKomnTpgDo6urmpWV+mup51apVtG3bFqVS+Vza5VatWhESEvLStMvz589n8ODB+Pv75/1enqZdtrCwyEu7bGZmppEuoqrbwnd1BSDt6hV06nsA0KuhHb8evsPuyw8Y0bpG3uBtQFgAXzT5AgOt6rHMmVA1da/ZvdSt8bKgUKjXnVi9ejVWVlb8/PPPXLt2jZ9++infsc+mGi7N+zFZWVlIpVIsLS3ZtWsXZ8+eZePGjVy+fJmxY8cWuK0gn3/+OTNnzqRZM3UK9Re7ep/ep6BUz69D2uWq2cJPiERqqIXM3Py5gdtalgbUtzNiR2Bk3jYxeCsIZSsuLg5HR0eAvFWoNMHV1ZXAwEBA3fXi4eHBqVOnOHXqFK1atWLatGkEBQUVuK0wbm5u2NnZcfjwYQA8PDzyZuukpKRw//59nJycCkz1/DqkXa6aLfwdo7HJlpHg6fncwC2oW/nf+93g1uMkalsZiMFbQShjPXr0YNKkSezdu5dBgwbh5+fHtm3bSnSNsLAwhgwZkvdznz59mDp1Kt999x0SiQQjIyNmz55NfHw8X375JcuWLUMikTBu3Disra3zbSvK+PHj6dy5M6DuavLw8GDQoEFkZ2czYcIEdHV186V6lslkr0faZU2l7SwLpU6PvOMjVdYPjqro339X3XCro8qOj8/bFZ2UrqoxxV81OyA4b9vfN/9WeazyUJ1+cPpVi1zhRNrY6kXUu3qp1OmRb926RceOHQtcymz9+vX079+fgQMHMmvWLM3e2L4J8ox4dGpYApB29VreLnN9bdq4mrPrciS5ueq+wu41u2Ola8Vvl38T+XUEQaiyyizgp6amMmPGjHyr2AAkJyezfPly1q9fz8aNG7lz585zI+OvzF49qq40TAaJhLSrV57b3auRPQ8T0jnz7xMAtGXajKw/ksCoQE4/OK25cgiCIFQiZRbwtbS0WLp0KZaWlvn2KRQKFAoFqampZGdnk5aWhpGRkeZubuFOrlwHWew1tGrWIO3q8/34nepaoa8tZ/szg7e9XHtho2fDr5d/Fa18QRCqpDIL+HK5vNDXprW1tRkzZgwdO3bkrbfewsvLK9/bba9EJifN1B0izqPj6UX6lavPBXGlQsY7HtbsufaQtEz1AspaMi1GeY7iasxVTkSKhc4FQah6KmSWTnJyMn/++Sd79+5FX1+fYcOGERISkjd6/azg4OBS3cPEqA66tzeTYO4N8fGEHD4MNjZ5+xub5bAlM4dVBy7RroY+AG65blhoWTDvzDzM6pq9ljN20tPTS/07e52Jelcvot6lUyEB/86dOzg4OGBqagqopy8FBQUVGPDd3d1LdY/wyAZIQjfg0tCRMMA2JQWjZ67l5qZi0dk4zkap+Ojd/9/+idYnTD81nSiDKNo5tCvVvStScHBwqX9nrzNR7+pF1LtoFy9eLHB7hbx4ZWdnx507d/JSowYFBeHs7KzRe6SZqnNxaMsfItHRyTcfXyqV0LOhHcdDY4hOysjb7l3TGwcDBzFjRxCK4VXSI4M6gVhBuW3at29PSkqKJov6HDc3N/7555+8n8+ePZsvv09x/fnnn7zxxhtkZ2cXuH/OnDls3769VNfWtDJr4QcFBTFnzhwiIyORy+Xs27eP9u3bY29vz9tvv80HH3zA0KFDkclkNGzYMC+Xhqbk6JiBsSOShxfRqVcv38AtQO9Gdvx25A67rzzgg1bqMQSFVMFoz9FMPTmVf8L/oYNjB42WSxCqksmTJwOwfft2QkNDmTRpUonOP3DgAB4eHpodwysGZ2dnlixZQtu2bZ9LZVAafn5+GBsbc+rUqULz9FQWZRbwPTw8WLt2baH7BwwYwIABA8rq9mr2TeH+GZRew4lbs5bczEykWlp5u/8/1UJEXsAHeLfGuyy9tpTfLv/GWw5vIZVUzQwUglAWcnJymDZtGuHh4WRnZzNu3DhatGiRL6XwgAED2LRpE6amppiZmeUlWytMUlISkydPJjExkaSkJGbNmkW9evWYOXMmQUFB5OTkMHDgQHr37l3gtmdZWlpSv359duzYQZ8+fZ7bFxAQwKpVq5DJZNSrV4+pU6dy48YNvvvuO7S0tNDS0mLBggUYGhpy8+ZNcnNzef/99/H3988L+Lt27WLZsmVYWVmhVCpxdXUlOTm5wDTRHTt2pF+/fuzduxcnJyfq1auX9//z5s3T6GdTNVMrPGXfFIK2oeNlT2xWFhnBwej8l13vqaepFkIfJ+FqpU6eJpfK+dDrQ6Ycn8LBewfp5NypIkovCCUSv3MnCds023Vg5NMb4/+SgRWXr68vFhYW/PDDD8TGxjJs2DB8fX3zpRR2cnKidevWdO7c+aXBHtRJ2Ly8vBg1ahS+vr7Mnj2bJUuWcOTIkbwcPTt27CA+Pj7ftoKMHj2awYMH4+3tnbctJSWFBQsWsHPnTvT09Pjwww85c+YMBw8eZODAgfTs2ZPTp08THR2NoaEhfn5+dO3alU6dOjF//nwyMjLyvhC2bduGoaFh3pdNdHR0gWmic3NzqVu3LiNHjqRdu3Z06tSJrVu30q5dOxITEzE0NCzR778oVbvpaq/OeKdjpk5K9GI/PkD3BrbIpJLn5uQDvOP8Di5GLvx+5XdyVbllX1ZBqCICAwM5dOgQQ4YMYfz48WRkZJCZmVlgSuGSCAoKonnz5gB5aYqNjY1xdnbmo48+IiAggJ49exa4rSBGRkb06NGDNWvW5G27e/cuTk5O6OnpAdCsWTOCg4Pp0KEDv//+O7/88gtmZmbUrFkTlUqFv78/3t7eGBsb06BBA44ePUpcXBx6enqYmZmhUCjyctgXlSba09MTiUSCmZkZdevWBcDU1FTjq2ZV7Ra+dX2QaaNIv4Xc0rLAfvy8VAuBkXzRyQ2ZVD0VUyaV8ZHXR0w8NpFdt3fRy7VXeZdeEErEuGfPErfGy4JCoeDDDz98ruUMFJhSuCQkEslzEymephletmwZ169fx8/Pj127drFixYoCtxVkyJAh9OnTJ2/SyIv3yMrKQltbmxYtWrB161YOHz7M5MmTmThxIgqFgidPnuQlY0tKSsLf358mTZo8lw756fWKShP97DjCq6aKLkrVbuHLtcDGCyIuoOPlWWDAB+jbxIEHCensCXr43PbOzp1paNmQ+RfnE5ceVx4lFoTXnpeXF4cOHQLUqzrNnz+f3NzcAlMKSyQScnJyinXd+vXr56UqvnnzJq6urkRERLBmzRrq1avHpEmTiI+PL3BbYbS1tRk+fDh//PEHoB7MvXfvXt4iLOfOncPDw4N169YRHx9P9+7dGTZsGMHBwfj5+fHFF1/kpUP28/Pj/PnzaGlpkZSURGJiIllZWVy6dAkouzTRJVG1W/ig7se/sBylRy+SDhwkOy4OuYnJc4d0rmdNTQs9Fh0KpauHDdL/WvlSiZRpb0yjn28/5l2Yx8xWMyuiBoLwWnnnnXc4c+YMAwYMICcnh7Fjx+atO/tsSmF3d3eaNGnCzJkz0dPTy5d3a+TIkXmtXW9vb4YOHcpXX33F0KFDSU5OZs6cOVhaWhIYGEhAQAAKhQIfH58CtxWlZ8+erFy5ElCvajVx4kRGjBiBVCqlcePGNGnShNTUVMaPH4+BgQFaWlrMnj0bHx+f51It6+rq0q5dO/755x/Gjh3L4MGDsbOzw/W/xZg0kSb6lWkgY2eZKXV6ZNUzaUSvbVOpvjFUJfuvU91wq6NKOnKkwON3BkaonCb5qfyvPsi3b8GFBSqPVR6qcw/Plbo85UWkja1eRL2rl0qdHrlS+C9zpo5+PEilBQ7cAnh72lLTQo+FB0Pz0iY/NdprNHb6dnx/+nsyczLLvMiCIAhloeoHfCN70LdGGnMF7Vq1Cu3Hl0klfNLelZuPk9h3/dFz+3TkOkx9Yyp3E++yPGh5eZRaEARB46p+wJdIwL6JOnNm40akXrpEblpagYd287KlhrkeCw/lb+W3smtFF+cuLLu6jLsJd8uh4IIgCJpV9QM+qLt1Yv/FsN2bqFJTST5ypMDDZFIJn3SoRcijJPbfeJxv/8SmE9GWaTPzzEyRZ0cQhNdO9Qn4gK5lNnIrKxL8/As9tJunLS6FtPItdC34tPGnnH10Fr9//cq0yIIgCJpWPQK+bQOQyJA8vIhh164kHztGTkJCgYfKZVI+aV+L4IeJHAjO38rvU7sPnhae/Hz+Z+LTC5/fKwiCUNlUj4CvpQdW9SDiPIbe70JWFon79xd6eHcvW5zNdFl0KDRf141UImX6G9NJzExk5lnRtSMIwuujegR8UHfrRFxEWccNLRcXEn0L75KRy6SMbe/K9QeJHAyOyrffzdSNsQ3Hsu/uPjbf3FyWpRYEQdCY6hXwM5OQPAnF0PtdUs+fJ+vRo0IP79nAFiczXRYeulVgK/59j/dpbdean87/xPUn18uy5IIgCBpRvQI+QMR5jN59F1QqEgP2FHq4XCZl7Fu1CIpMxO/qw3z7pRIps1rNwlRpyhdHviApU7NZ7QRBEDSt+gR8s5qgYwIR59FydkZZvz6JfkXPtOnV0A5PeyO+871OXEr+N2xNlCbMbTuXRymPmH5yuujPFwShUqs+AV8i+W8FLHW2PSPvd0m/cYOMf/8t9BS5TMocH0/iU7OY4XejwGMaWDZgfKPxHLx/kA0hG8qk6IIgCJpQfQI+QM0OEHMTom9i8M47IJGQWMScfAB3G0M+fqsW2wMjORySfwAXYFi9YbSzb8fcC3O5Fn2tLEouCILwyqpXwK/XEyRSCNqGwtIS3Teak+Dv99KumDFv1cTVUp+vd1wjKT1/DmuJRMLMVjOx1LHki6NfkJBR8Bx/QRCEilS9Ar6BNTi3gmtbQaXCyNubrHv3SQ8KKvI0bbmMn/p48igxnTl7Qwo8xkjbiJ/b/kxUWhRTjk8hOze7LGogCIJQatUr4AN49IHYO/DwMgZvv41EoXjp4C1AQ0cT3m/pwroz9znz75MCj/G08GRKsykcjzzOrLOzxCCuIAiVSvUL+HW7g1QB17YiMzREv11bEgICUBVjmbUJndxwNNVl8rarpGUWfHw/t36MqD+Crbe2suzaMk2XXhAEodSqX8DXMYFaHeH6DsjNxfBdb3KiY0g9d+7lp2rJ+NGnPnefpLLg4K1CjxvXcBzeNbxZFLiI3Xd2a7L0giAIpVb9Aj5A/T6QGAn3T6Pfri1SPT0SitGtA/BmTXMGNnNk2fF/uRxecPI0iUTC929+T3Ob5nxz8htOPTilydILgiCUSvUM+G7vgEIXgrYiVSoxePttkvYfIKiLfJsAACAASURBVDc9vVinT+laBxsjHcasv0RsAS9kAShkCha0W4CLsQufH/mckNiCB3sFQRDKS/UM+Fp66qB/fSfkZGHs05vcpCQSdu4q1umGSgW/D25EdHIGYzdcIjsnt8DjDLQM+K3Db+gr9Pn44Mc8TM6fokEQBKG8VM+AD+rZOmmx8O8RdJo0QenpyZOVK4o1eAvgaW/MD73qc+rOk0KnagJY61nze8ffSc9OZ/TB0USlFvzyliAIQlmrvgG/VgdQGsG1rUgkEsw++ICse/dJOnio2Jfo09ie9950ZunxMHZdjiz0OFcTVxZ3WMzjlMcM3TOU8KRwTdRAEAShRKpvwJdrg3s3CPGDrDQMOnZA4eTIk2XLSjR//ut33WnmbMqkbVe5/qDwN2wbWzVmeeflJGclM2zPMELjQjVRC0EQhGKrvgEf1N06mclwax8SmQyz4cNJv3aN1PPni30JhUzKr4MaYaKrxei1FwvMqpl3O3MPVnVeBcDwfcNF3h1BEMpVmQb8W7du0bFjR9atW5dv38OHDxk4cCB9+vRh+vTpZVmMwrm0AT1LCNoKgFHPnshMTXmyfHmJLmNhoM0fgxsTlZTBJxsDCx3EBahlUovV76zGQGHAiP0jOPfw5fP/BUEQNKHMAn5qaiozZsygRYsWBe7/8ccfef/999m6dSsymYwHDx6UVVEKJ5VBvV5waz+kJyBVKjEdMpiUo8dIv1n4i1UF8XIwZmZPD07cjmFWQHCR3UIOBg6sfmc1tvq2fHTwIw7fP/yqNREEQXipMgv4WlpaLF26FEtLy3z7cnNzuXjxIu3btwfgm2++wdbWtqyKUrT6fSAnA0LUaZJNBg5EoqND7IoVJb5UvyYOvN/ShZUn7/LLwaL76C11LVnZeSW1TWrz2ZHPWHdjnci9IwhCmSqzgC+Xy1EqlQXui42NRU9Pj9mzZzNw4EDmzZtXVsV4OfumYOyozqAJyIyNMe7bhwR/f7Ielnze/NR33enb2J6Fh0L5/cidIo81VhqzrPMy2ti3Yc75OXx94mvSs4v38pcgCEJJySvipiqVisePHzN06FDs7OwYNWoUR44coV27dvmODQ4OLtU90tPTi32uhU07zELWc/viUbJ1LaFlS1i3ntsLFsDw4SW+97C6CqKe6DFnbwgJsdH0cDcq8vjR1qOxyLXg73//JuhREF+6fom5tnmJ7wslq3dVIupdvYh6l06FBHwTExNsbW1xdHQEoEWLFoSGhhYY8N3d3Ut1j+Dg4OKfa/0F3NyA62M/6PozuLsT2bUryQcPUWvqVGSGhiW+/7I6dRiz/hJ/nHuMs70tA5o5Fnl8vbr1aBPehsnHJ/N1yNfMazePptZNS3zfEtW7ChH1rl5EvYt28eLFArdXyLRMuVyOg4MDd+/eBeD69eu4uLhURFHUTJygwSC4uAoS1YPHZh+8T25qKnGbNpfqkgqZlMX/a0jb2hZM2XGNnYGFv5j1VFuHtmx4dwPGSmNG7h8p+vUFQdCoMgv4QUFBDBkyhB07drBmzRqGDBnCypUrOXDgAABfffUVU6ZMYcCAARgYGOQN4FaY1hNAlQsnFgCgdHdHr2VLYteuITcjo1SX1JbL+HNIY95wMWPClivsufbyMQEXIxc2dN1AW/u2zDk/hwlHJ5CYmViq+wuCIDyrzLp0PDw8WLt2baH7nZyc2LhxY1ndvuSebeW3+gwMbTEb8QH3h79P3IaNmA1/r1SXVSpkLBvWhCHLzzJ2YyA/Zebg09i+yHP0tfRZ8NYCVgatZEngEq7HXGdOmzk0sGxQqjIIgiBAdX/T9kUvtPJ133gDvbZtiFmyhKzHpU96pqctZ/X7zWjuYsqELVf482jRs3cApBIpH9T/gNXvrEYikfDe3vdYenUpObnFS+4mCILwIhHwn/VCX75EIsH6669RZWUR9fPPr3RpA6WClcOb8m59G2bvCWGW/w1yc1/eP+9p4cmWblvo5NSJRYGLGH1AZNwUBKF0RMB/0QutfC1HR8xGfECinx8pxVgGsSjachmLBjZkaAsnlh4PY8KWK2QVkYbhKQMtA+a0mcP3b37P1Zir9Nndh0P3i5/VUxAEAYoZ8IODgzlx4gQAv/76Kx9//HGh035eewXN2Bk5EoWdHY9nzECVlfVKl5dJJXzXvR4T3q7NjsBIRqy+QGpm9kvPk0gk9HLtxSbvTVjpWfHp4U/58uiXPEl78krlEQSh+ihWwP/uu+9wdnbm5MmThISE8M0337B48eKyLlvFeaGVL9XRweqrKWSE3iZ23fpXvrxEIuGTDq7M7l2f46HRDFx6lqik4r1hW8OoBhve3cDYBmM5dP8QPXf1xO9fPzF9UxCElypWwNfS0sLe3p4DBw4wcOBArKysyM19eVfEa6uAVr5++/YaGcB91sBmjvw2qDE3HyXSffHJQhdFf5FCqmC012i2dNuCo6EjU45PYew/Y3mU8kgj5RIEoWoqVsBXKBRMnTqVCxcu0Lx5c44dO0Z29su7IV5rL7TyJRIJ1l99hSoz85UHcJ/VxcOabR+9iUwqod8fp/n7fPFXw6ppXJM1XdYwselEzj08R89dPdkftZ9cVRX+MhYEodSKFfAXLlxI27ZtWblyJTKZDIVCwc8aDHqV0rOt/IQIALScnDAbOUIjA7jPqmdrhO8nrWjqYsLEbVeZviuoWIO5ADKpjCF1h7C9x3Y8zDxYdncZQ/YMISS28HV2BUGonooV8MPDw9HR0cHCwoJff/2VtWvX8uhRNeg+aPMFSGTgOx7+6yM3GzkSha2tRgZwn2Wqp8Xq4c0Y2dqFNafvMWjpWaKTiv+Gr4OBA0s7LWVsjbFEJEXQ368/c87NISUrRWNlFATh9SYGbYti7Ahvfw+3D6pb+vw3gPv1V2SE3ubJipUavZ1cJuXrd+uycEADrkbG023xCS7djyv2+RKJhDbmbdjdczd9XPuwPng93Xd2Z//d/WJQVxAEMWj7Uk1HgEtb2Pc1xIYB6gFcgy5diF64UKNdO0/1aGDH1g/fRC5T9+svO/5viQK2kbYR01pMY13XdZgqTZlwdAIfHfqIO/Evf8NXEISqq0SDtufPn68+g7ZPSaXQ8zf1coi7xkBuLhKJBJuZM9ByciLy8wlkRWn+zVcPOyP8P2lN+zqWzPQPZuSaiySklqwLydPCk43vbmRS00lcjbqKz24fZpyeQUxajMbLKwhC5VeiQdvVq1dXn0HbZxnZwztz4N5JOPMbADJ9fewXLSQ3JYXIzz/XaH9+3m11Ffw5pDHTvOty5GYUXRcdL/bUzafkUjmD6w7Gv7c//d36sz10O947vFl6dalYXUsQqpliBfzc3FxCQkKYPn06Y8eO5cqVKxgbG5d12SoXr4Hg1hUOfQ9R6hkw2q6u2Hz/HWkXLhK14Jcyua1EIuGDVi5s+VC9GHzfP06x/ERYifvkTZQmTGk+hR09dtDMuhmLAhfRbWc3fO/4immcglBNFCvgT5o0CX19fcaMGcOIESOQSqVMmTKlrMtWuUgk0G0haOvDjtGQo27RG3Xrhsn/BhK7YgWJ+/eX2e0bOprgP64VbWtbMsPvBh+svkBUYslb6M5Gzixqv4gVnVdgqjTlqxNf0de3L8cijomBXUGo4ooV8FNSUhg+fDj16tWjQYMGjBo1isTEargoh74leC+Ah5fh+P8vvG45eTJKT08eTvmKjLCwMru9sa4WS4c2Zrp3XU7ejuHtBcfYdTmyVIG6qXVTNr67kTmt55CWncaYQ2N4b+97BEYFlkHJBUGoDIrdpXPt2rW8n69cuVJ9Zum8qG4PqN8Pjv0MkZcAkGppYf/LAiQKBZHjPyU3La3Mbi+RSHi/lQsB41tTw0KP8Zsu8/H6S8Qkl3xVLqlEStcaXdnVYxdTm0/lftJ9hu4ZyieHPuFW3K0yKL0gCBWpWAF/+vTpzJ07l1atWtGqVSsWLlzIuHHjyrpslVfXn0DfGjYNggT1WrUKW1ts584lIzSUh19/jaqMvxBrWuiz9cM3mdSlDoeCo+i84FixllAsiEKmoH+d/vj38md8o/FcfHyRPrv7MPHoRDGVUxCqkGIF/Nq1a7N69WpOnDjBiRMnWLFiBYsWLSrrslVeOibwv82QkQQb+kG6untLv1VLLCd8TmLAHh7NmFHmfeIyqYSP2tXE95NW2Bgr+Wj9JWYffVzszJsv0lXoMqL+CPb47OF9j/c5EnGEXrt68eXRL7kdd1vDpRcEobyVegGUaj/AZ+0B/VZDVDBseS9vENdsxAjMRo4gfuMmosto5s6L3KwN2PFxSz5/uzan7qfQcd5R1p+9V6wVtQpipG3Ep40/ZZ/PPj6o/wHHIo7Re3dvvjj6hQj8gvAaK3XAl0gkmizH66lWB+j2C9w5BP6f5+Xbsfj8c4z79+fJX38Rs3RpuRRFIZMyroMrv3e3p56tEV/vCKLPH6cIeVT6wXUTpQnjG41nn88+RtQfwfGI4/Te3ZvPj3xO8JNgDZZeEITyIC9qp4+PT4GBXaVScffu3bIq0+ul0VCIuwfH54KJM7SeoE6lPH0aucnJRM+bj8zAAJMBA8qlOPZGWmwY6cn2S5HM9L+B96ITjGhdg/EdXNHRkpXqmsZKY8Y1GsfQukNZc2MNG0M2cuDeAVrbtWaU5ygaWDbQcC0EQSgLRQb8at1PXxLtp0L8PfVLWcZOUL8PEpkM2x9nk5uczKPvvkeqp49RN+9yKY5EIsGnsT1v1bFkdkAwfxy9g++VB0zzdqdzPetS/3X2NPC/5/Eem0I2sfbGWobsGUIz62aM9BxJc+vm4i8/QajEigz4dnZ25VWO15tEAj1+Va+OtfMjMLAB55ZIFArsFv5C+MhRPJg8GameHgbt3yq3YpnqafFzXy98Gtvzza7rfLjuEm/WNOObbvVwszYo9XUNtQwZ5TmKwe6D2XprK6uur2Lk/pF4mnvyQf0PaOfQDqmk1L2FgiCUEfGvUlPk2tB/nbpbZ0M/uKte9F2qVGL/+28o3d2JGD+exICAci/aGzXM8B/Xiu+61+P6g0S6LjrOt7uvlzgZ24t0FboMrTeUPT57mPbGNJ6kP2H84fH47PbB944vWbmazy8kCELpiYCvSbqmMHQ3GNrBOh91Hn3UidYcly9Dx9OTyAlfELtmbbkXTS6TMuxNZw5/0Y6BzRxYc/ou7eYeZv3Ze+SUcjbPU9oybfq59cOvlx+zW88G4KsTX9FtRzc2hWwSSdoEoZIQAV/TDG1geACYu8LGgRDsB4DMyAjH5csw6NiBxz/8QNS8eRUytdVUT4uZPevj90lrXK0M+HpHEO8sPMbhkKhXLo9cKse7hjfbum9jcfvFmOuYM+vsLDpv68xvl38TaZkFoYKJgF8W9MxhmC9Ye8LfQ+HaVkDdvWP3yy8YD+jPk6XLeDh5SpmkVS6OuraGbB71Br8PakRmdi7DV51n0LKzBEUmvPK1pRIp7RzasfadtazovIL65vX5/crvdNraia9PfC3W2xWEClLkoK3wCnRMYOhO2DAAto2ArDRoNASJTIb1N9+gsLIieuEisp88wX7hL0j19Mq9iBKJhHfq29DB3YoNZ++x8FAo3otP0KuhHV90dsPOWOeVr9/UuilNrZtyN+EuG0I2sPP2Tnbf2U0TqyYMrjuYdvbtkElLN11UEISSkX377bffVnQhCvPw4UNsbW1LdW5MTAwWFhYaLlEJybWhXi94EAhnfgWlCdg3QSKRoNu0KXIrK+LWriXl5En027ZFpq//yrcsTb1lUgkNHE34X3NHAP6+EM6qU3eJT82inq0hulqv3i4wVhrT2r41/ev0x1RpyqkHp9hyawt+//ohkUioZVwLhUxR6utXis+7Aoh6Vy/FrXdhsVN06ZQ1LV0YuBHqeMPeSRAwEXLUy0Oa9O2L/ZIlZPz7L2E+fUg9f75Ci2qoVDCpSx0Of9GO7l62rDwZRpufDjNnbwhxKZmauYeWIcPqDcO/tz/z2s7DXMecH8/9SMctHZl/cT6PUh5p5D6CIOQnAn55kGtDvzXQYiyc+xPW94G0OAAM2r+Fy+ZNyPT1uffecGJXr67wPEW2xjrM7evFgc/b0tHdij+O3qH1T4eZf+AWiemaGXOQS+V0cu7E2q5rWdd1HW/avcnq66vpsq0LE49N5Gr0VY3cRxCE/1emAf/WrVt07NiRdevWFXrMvHnzGDJkSFkWo3KQyqDzLOi+RD1Hf1lHiFEnItN2dcV5y9/ov9WOx7N/5MGEL8hNSangAqtTMC8a2JC949vQ2tWcRYdCafXjPyw+FKqxwA/gZeHF3LZz2dN7D4PdB3M84jiDAgYx0G8gu+/sJiOn5Ln+BUHIr8wCfmpqKjNmzKBFixaFHnP79m3OV3A3RrlrNASG7Va38Je1hzv/ACAzMMB+0SIsPv+cxL17uTtgAJmVJF+Rm7UBvw9ujN8nrWjmYsq8A7do9eM/LDwYSkKa5gK/rb4tXzT9goN9D/J1869JzU7l6xNf02lrJxZdWiS6ewThFZVZwNfS0mLp0qVYWloWesyPP/7IZ599VlZFqLyc3oSRh/97QasPnP0TVCokUinmo0biuGwp2dExhPXpWyFv5hbGw86IZcOa4vdJK5rXMGPBQXXgn7//JvGpmunjB9BT6DGgzgB29tjJ0k5L8bLwYnnQcrps68LnRz7n/KPzFd7tJQivI4mqjP/lLF68GBMTEwYPHvzc9u3btxMTE0PXrl2ZMmUKa9fmf/v04sWL6Orqluq+6enpKJXKUp1bXqRZKdie+QaDBydIcOzEoyaTyFX8Nz0zKgrmzYdbt6BNaxg5Eooxi6c8630nNoONV+I4eT8VHYWE7nWM6FnXCGOl5qdZRmVEsT9qP/9E/UNyTjIOOg50sepCa7PWKGXK1+LzLgui3tVLceudmppK48aN822vkHn48fHxbN++nZUrV/L48eMij3V3dy/VPYKDg0t9brny8IUT8zA6/ANGybehz0qwbQDu7qhatiTmr7+I+fU35LdCsZ39A3pFdJFB+dbbHfBuCSGPEll86DZ/Bz1kd0gSg5o7MqpNDSwNNfcP0h132tKW9Ox09oTtYWPIRpbeXcqmyE30dO1JU3lT3nIvv8R0lcVr85xrmKh30S5evFjg9jKfh3/u3Dl0dHTw9PTM23bkyBGOHDmCn58fvr6+3L59mydPntC6devnzn3t5+EXh0QCTi3BpQ0EbVfP4lEag10jJDIZek2bot+mNcmHDxO7ejW5ScnoNmuKRF7wd3VF1NtcX5t3PW3w9rQhPjWLTf/N449KzKC2lT6GOqWfX/8iuVSOu5k7fWr34U3bN0nITGDX7V34P/bnctRldOQ6OBg6IJNUj5e5XpvnXMNEvYtWWOyskIBfq1YtBg0aRN++fWnVqhVXr15lwYIFxS50cbx2D4SxA3gNhMfX4ezv8DgIarYHhQ4KKyuMfXzITUoibt06kg4eQMfTC0UB4yMVWW9TPW06e1jTs4EtqZnZ6he4Tt4lPDaVmpb6mOppaexeEokEaz1r3nZ6Gx9XH9IT0rmccJltodvYHrqdpMwkHAwcMNAqfRro18Fr95xriKh30co94AcFBTFhwgTOnTvHtWvX2L9/PwkJCcTExFCzZs284xITEzl06BC9e/cudqGL47V8ILR0oX4f0DaA88vUOXhsvMDYEYlCgX7btuh4eZEUsIfYNWvIiU9Ap1FDpFr/H0grQ72NdbXo6G5Fn8b2ZOWo2HYpgpWn7nLrcRJOZnoa7eoB9SCvRYYF41uPx8Pcg6i0KHaE7mB9yHpuxNxAT6GHvYF9lczRXxk+74og6l20wmJnmQ/avoqLFy8WOPBQHK99H1/ERdj2PsTdhWajoeM3oKUe0M1JTCT6l1+I27gJubk5Vl9/hUHnzkgkkkpZ7+ikDFaeDGPt6XskZWTT2tWcMW/VormLqcZWyHqx3pHJkWy7pW7tP0l/gqWuJb1de9O7Vm9s9G00cs/KoDJ+3uVB1LtohcVOkUunsjK0Va+Xm5mi7te/thWs6oGJE1JtbfTbtkW/TWtSzp8jbu060q5eRadhA+IyMytdvfW05bSsZc7gFk4YKOUcuPGYNafvcTw0GkOlghoW+khfMfC/+HkbahnS3KY5g+oOwt3UnUepj9gZupN1weu4GnNV3ddv8Pr39b/2z3kpiXoXrcL68F9FtQ74ADItcH0bXNrCrT1w5jdIjlbP45dr5/Xty4yNSdixg7j16yEnF7PmzZEoNDdQqinachlNnU0Z2sIZS0NtjoXGsPFcONsvRZCrUuFqpY+2vHQBuLDPWyaRUcO4Bt41vOlRqwe6Cl1OPjjJttBtbLm1hajUKMx1zDHXMX/V6lWIKvGcl4Kod9FEwH+dGTtAw6GQlQ7n/lK39s1rg1kNJFIpOl5eGPXsSVZ4BJm7dpGwaxcyY2O0a9eulIuKy2VSvByMGfamM3VtDAiNSmbT+XDWnr5HdHIGNcz1MdIt2RdWcT5vAy0Dmtk0Y5D7IOqb1ycxMxH/f/3ZdHMT/9z/h/TsdOwM7NBVlO7dj4pQpZ7zEhD1LpoI+K87mQJqdYAab0HoPvVMnkdBYNcEdIyR6etj+E4XYqyt0fo3jPgNG0k+fAQtFxe0Kuli9FKJhFqWBvRr4kD7OpYkpGWx9WIEK06FERSZgIGOAidT3WJ9aZXk85ZKpDgbOdPZuTMD6gzARs+G2/G32XF7B+turOP6k+soZUrsDewrfZdPlXvOi0nUu2gi4FcVRvbQeBgodODyenWLX6UCu8YgkxMjkVDrow/RcnYm6fBh4tauJT04BGVdd+QmJhVd+kJZGSrp4mFDvyYOaMulHAqOUnf3BEaQkZVLDXO9IvPyl/bzVsqVeJh74FPbhy7OXdCWa3Mi8gTbQ7ez5dYWYtNjsda1xkRZOX93VfY5fwlR76KJgF+VSOXqfnyvARB/H84vhaCtYOJCjMoYC0tLlG5umAzoj1SpQ+KuXcSuXUvWg0i03eogMzSs6BoUSl+pHuB9700XalsZEBaTwub/5vPfjk7GTE8bW2Nlvla/Jj5vE6UJLWxbMNh9MPXN6xOfEY/vHV82hGzg1INTZOdmY6dvh1JeeV7pr9LPeRFEvYsmAn5VpDRUr6jl2ALuHIZzf6ATex0th0agb4FELke3SROMfXxQZWaSsG07sevXkx31GGWdOhpZYausyKQS3KwN6NvEAW9PG1RAwLWHrD97n4BrD8nJVVHDXB+lQt3losnP+2mXTxeXLvSt3RdzHXOuRl9l552drL2xlmsx1wCw17d/pVW6NKFaPOcFEPUumgj4VZmJMzQaBkojZDe2Iz33J8SHg00DUBoi1dVFv01rjHr3Ijc1hfht24lbt47s2DiU7nUqZD3dkjDV06admyXvvemMk6keIY+T2Hw+nFWnwrj7JBVzA23kmUll8nnrKnRpYNmA/m79ae/YHl25LmcfnWXn7Z2sD15PaFwocqkce337Clmbt1o9588Q9S6aCPhVnVQGDs0JNWyJuYkRBK5R9+9nJINtQ1AokenrY9CuHUbdu5OTmED8lq3Erd9AdnQM2rVqVuquHgCFTEo9OyMGNnOko7sV2bkq/K48YN2Z+5y+n4pUJsPFQq/UUzuLIpFIMNcxz+vyecPmDWQSGUcijrDj9g423dxEZFIkhtqGWOtal9vsqGr3nP9H1LtoIuBXE9FxSVi80V/dv58cDReWw6VV6n5/6/ogUyAzNMSgQweMvN8lJzGR+O3b1X389++hcHJCbmZW0dV4KUtDJR3crRj2pjN2JjpcvveEbZcfserkXe7HpmBhoMTKULtMAq9EIsFW35Y29m0YUncInhaepGWnse/uPrbc2sLuO7uJTY/FXMccU6Wpxu//rOr6nIt6F00E/Goir95KI3DvBm5dITpEHfgD16oDv5WHOvAbG2PQoQPGvXpBrooEXz/i1qwl/foNFLa2KGwqfwoCLbkUT3tjmppk0K9VPbJycvG9+pC1Z+6x/8ZjVCoVzuZ6eX39miaTyHAydOJtp7cZ5D6IGkY1iEqNwvdfXzaGbGT/3f1Ep0VjpG2EmdJM419A1f45r2ZEwC+EeCD+Y2Clbu07tyk88BsYoN+6Fcb9+iHV1SFp337i1q8n5cRJpPr6aDk7I5FW7sRjMTExeNR0oGNdK4a2cMLOWIegyAT+vhDBypNhhD5ORl8px8GkePP6S0NLpoWbqRvdanajb+2+2OjZ8Cj1Ef7/+vP3zb/xvePL49TH6Cn0sNS11Eg5xHNevYiAXwjxQLzA2BEa/A+cW0NUMFxYoQ78EhlY1QWZFlIdHfSaNcPkf/9DbmZOypkzxP/9N/E7dkJONtq1aiHV1i7/ShXDs/XWlsvwtDfmf83Vff0SCewNesSm8+FsuRBOQloWdsa6JX6btyR0Fbp4WnjSo1YP+rv1x9nQmdiMWALCAth6ayvbQ7fzMOUhOnIdrHStSp3JUzzn1YvIllkIkU3vJe6egCM/wt3joGMKzUap/9P7//57VU4OyUeOELt6DannziHR1cW4Z09MBg9Gu4ZLGdai5F5W7/SsHA7ceMyWixEcD41GpYJmzqb0bmRHV08bDJXlM70yMTORo+FHOXjvICciT5CZm4mZ0oyOTh3p6NSRJlZNkEuLvxCdeM6rl1fNlikCfhVT4nrfPwMnF8LNAJDrQKMh0GIsmDg9d1j6jRvErllLor8/qqws9N5sgfGAARi0b1/o6lvlqST1fhCfxo7ASLZdiuDf6BS05VLermuFTyN7WruaI5eVT/dVSlYKxyOOs//efk5EniAtOw1jbWPaO7ano2NH3rB546Xz/MVzXr2IgF8I8UCUUFQInFoEV/8GVa76ha4WY8Cu0XOHZcfEEL91G3GbN5P98CFyKyuM+/XFuG/fAlfgKi+lqbdKpeJqRALbL0Ww+8oD4lKzMNfXppuXDT0b2OFpb1Ru0yvTzZwjpAAAIABJREFUstM4EXmCA/cOcCziGClZKRgoDGjr0JaOTh1paduywDd8xXNevYiAXwjxQJRSQqQ6MduFlZCZDPbNoPloqNtDncDtP6rsbJKPHSNuw0ZSTpwAuVw946dPH/Ravlnug7yvWu/M7FyO3Ixi+6VI/gmJIjMnFxdzPbp72dKzoR0u5uX3clpGTgZnHpzhwL0DHA4/TGJmIjpyHVrbtaajU0da27VGX0v9lrR4zqsXEfALIR6IV5SeAJc3qF/eiv0XDGygyfvQ+D3Qf74ln3nvHnGbNpOwYwc58fEobG0x6t0b4969UJRy0L2kNPl5J6RlsTfoITsDH3Am7AkqFXjaG9HdyxZvT1usjcovl05WbhbnH53n0L1DHLp/6P/aO/OguK4r/3+6aeimu9mhWcS+I4GQQCCBEDLabHlsJ+PYYyejOJ5kPJ5SueL8Mk5GiTM1qZqxYzuujBOVJ3HZ4yx2PHbiJB7JsWwt1soOskBsAoTEvguxd9PL+/1xERICZEtiE9xP1auG91439/Bef8+75557Lr3mXpzVzmQEZbAtdBtBo0GsX71+3tqzWJDf7xsjBX+ZMOt2OxxQfxgKfwXnj4hFWVZ+WYh/6Aa4JuThGBtj6NNPufzH9xnOywPAkJWF51e+gnFLzqS1d2ebubreHf1m9pe18cGZVirbBlCpxGDvA2uC2JkYOKsLs38edoed8p5yDjce5kjTEVqHWlGhYq1pLZtDNrM5eDORHpGLcg2E2UZ+v2+MFPxlwpza3VMnnvjL3gXLAPjFC+Ff/Qi4ek46dayllf4//5nLf/4zto4O1B4euO+8B48vfQnXNWtmXZTm43qf7x5if1kb+8raaOgeRqNWkRXjy/2rg9ixyh+3ecr0ATH+UHOphj+c/gOV5kqqL1UDoqDbFfFf579uwYu7zRXy+31jpOAvE+bF7rFhqPizyOVvOy2yexIfFOGe4LRJT/2K3c5wXj79+/YxeOgQitmMc1goHg88gMeXvoRLcPCsNGk+r7eiKFS3D7KvrI39ZW20Xh5Fq1GzNcHEA8lB3BVnmrOZvddzxe6O4Q5OtJzgeMtxCtsLsdgtGJwNZAZlsjl4M5uCN815mYf5RH6/b4wU/GXCvNvddgZKfw3lfwTrsFh6ce0uWP2omOV7DfahIQYPHqL/gw8YKSoCwDUlBY/778Ptnntua4GWhbreiqJwuuky+8va+LC8jZ6hMdy0GnasCuCBNUFkRvngPIdpntPZPWobpbC9kGPNxzjRcoLu0W5UqFjtt5q7Qu4ia0UWcV5xd3ToR36/b4wU/GXCgtltGYTKv8Bnb0NzoZjBG7MD1v49xNwNmsmxbmtrK/37P6T/w/2M1Z8HjQbjxo24338/bltyUOtvbl3ZxXC9bXYH+Q297DvTxseVHQyabXgbXNiZGMB9q4NIj/DGST2/oSyH4qD6UjUnmk9wrOUYVb1VAPjofMgMyiRzRSYZgRn4uC7+gnnXshiu90IgBX8G5A2xgPTUCeEvexeGOkDvA4lfETV9glImh3wUBcu5c/Tv38/AXz/C1tGBSq/HLScH9533YNi06QuVc1gUdl+D2WrneG03H5a3c7iqk1GrHZOblnuTArk/OYiUUM9ZecK+Wbu7R7rJa8sjty2X/LZ8LlsuA5DgnUDWiiyyg7NJ8k1akNr+N8Niu97zhRT8GZA3xCLAboPzn4q1d88dALsFfGIg+REx0OsZOul0xeFgpKSEgQ//yuDBg9gvX0ZtMGDcskWI/8aNM4r/orL7OkbGbByp7uLD8jaOnutmzOZghacr960O5L7VQSSucL9l8b8dux2Kg+reanLbcsltzaWsuwy7YsdL68XGFRvJDs4mMygTD63HLX3+XLKYr/dcIgV/BuQNscgYvQxV/yee+ptEyiZhGyHpYTGpSz95QFGxWhkuKmLw448ZPHgIe38/aqMR45Yc3O++W4i/7mo+/KK1+zoGzFYOVXbyYXkbJ+t6sDkUwn303Lc6iPuTg4gLcLupz5vV+QeWfvLa8jjRcoJTrae4bLmMk8qJZL9kNgRuYEPQBhJ9E3FWL3zmz51yvWcbKfgzIG+IRUzfRTHIW/4e9NaJUs1RW4X4x+0E7eS1dhWrleGCQgYOHGDwyBEc/f0i7HPXZtx23I0xexPnGhsXv93X0Tc8xieVHXxY3k7e+R4cCkSbjNybGMDOpEDiA9w+98l/rq633WHnbM9ZTrScIL8tn8reShQU9Bo9aQFpwgEEbiDKM2pBBn/viPt8DpCCPwPyhrgDUBToKIez74s0z4EWkeIZt1OkeUZvA2fXyW+xWhkuLGLw4EEGDx/GfukSKp0OJTmZoAf/FuPmzTh5es7wBxcv3YMWPq5o56OzHRRe6MWhQKSvgZ1JAexMDGRV0PRhn/m63v2Wfoo7iiloL6CgvYDGgUYAfF19WR+4nvUB68kIyiDAEDDnbYE77D6fRaTgz4C8Ie4wHA6R3VPxvsj2GekFFyPE3i1CPtHbwWVy5o5iszFSeprBTz6h7+OP4dIlcHJCn5aG27ZtuG3dckes2nU9PUMWDlZ28tHZdvIberE7FEK8XdmZGMjdqwJYG+KJejzbZ6Gud9tQG4XthRMO4JL5EgBh7mFsCNxARlAG6QHpuLncXIjqi3LH3ue3iRT8GZA3xB2M3QaNp4TwV+8X4u9sgNgdoqxD9LYpYZ/qykrC7XYGDx9h8MgRxs6fB0C3ahXGnBzctuSgTUi443LPLw2PcaiqgwMVHeTW92C1K/i7a7l7VQD3JAbgbu4icdXKBW2joijUXa6joK2Awo5CijuKGbWNTsT/M4Iy2Bi0kZU+K2ct+2dJ3Oe3gBT8GZA3xBJhQvw/GBf/HtDoIGqLWLM39h7Qe0+x29JwgaFPjzB4+AijZWWgKGgCAjDm3IVbTg769esX7epdMzFgtvJpdRcfV3RwrLYLs9WBu1bNPUmirk9mtA9azcKnU1rtVs50nyG/LZ+8tjyqeqtQUPDQepAekM6GwA2sD1xPqFvogmQn3cksasGvra1l9+7dPP744+zatWvSsYKCAn72s5+hVquJiIjgueeeQ31dSV0p+DfPkrbbboPmAiH81fthoFVM8ArPosMrjYDN/wAeU0s12Hp7GTp2nKFjRxnKzUMZGUGl12PYsAFjdjbG7E3zVtVzthgds3O8tot3c2spbTMzaLHhptWwJcHEPasC2Bznh95l4RemAegz91HQXkBeWx4F7QV0DHcAEGgIFPH/8TEAP/0XX7JwSd/nN2DRCv7IyAhPPvkk4eHhxMXFTRH8HTt28Lvf/Y6AgAC+/e1v85WvfIXNmzd/oUZ/EeQNscRRFFHHp/pDqN4HvfVif+AaiP8bsZlWTprkBeCwWBgpLGTw6FGGj5/A2tYGgDYmGkN2NsZN2ehT1qKaw8qes0l1dTWRMbHkne/l47MdHKzqoG/Eis5ZTVa0HztW+rMlwYSvcXH0ZhRFoWmwaSL8U9heyMDYAACRHpET4r8uYN0N8/+XzX1+HYtW8G02Gzabjddffx0vL68pgj80NITRKOKwP/7xj1mzZg1f/vKXv1CjvwjyhlhGKArniw4QNVYjlmpsKRb7PcOE8MfeA2GZkxZwEW9TGGtoYOj4CYZOnmCkpBSsVtR6PfqMDIxZGzFs2jRrBd7mguuvt83uoOjiJT6p6OBwdRetl0dRqSAl1IvtK/3ZluBPtMl4g0+cX+wOOzV9NRS2F1LUXsTprtOM2kZRoSLBJ2FC/Nea1k4aAF6W9zm3L/hz1ufTaDRobrDW6RWx7+rqIjc3l6effnqumiJZ6qhUjLlHQMK9sOm7MNghZvae+wiK34CC/watO0RvFeIfvR0MPqhUKrRRUWijovD55j9gHxpmpCCfoZOnGD51iqEjRwBwCQvDsGkTho2ZGNLTURvmb/Wrm0XjpCYzypfMKF9+/IBCVfsAh6u6OFTdwQsHanjhQA1RfoaJQd+kFfO3jON0OKmdWOWzilU+q/hm4jex2q2U95RT1F5EQXsBb1W/xa8rf41apSbeO540/zTSAtIw2BbvNVjMzPmg7d69e6d9wgfo7e3liSee4Lvf/S5ZWVlTjpeWlqK/ySJaVzCbzeh087cy0WJB2j0ZlXUEQ1cJbq0nMbbnoTH3oqjUjPokMhS4kaHATCye0VNCPyJk1AafnYEzn8HZChgbA40GYmNhTTIkJ0NUFDgt3EDpzVzv7mEbBc3D5DWNUN4xikMBP4MTmaEGMkMNrDLpZr242+1isVuoG66jaqCKysFK6ofqsSpWVKiINkST5JFEskcyMYYYNOrFMWYxl3zR6z0yMrIwWTozCf7Q0BCPPfYY3/nOd8jOzp72vTKkc/NIu2+AwwHtZ6D2E6g9AO1lYr9bIMRsF9U9IzaDzn3qWy0WRk+fZjgvj+HcPMxVouqk2t0dw/r16DM2YNiwAZeIiHl9Yr7V6903PMaRGpHxc6JO1Pfx0juzJd6f7StNbIrxw6BdfAJqsVso7y7no7MfUWet42zPWRyKY2IGcEZQBhsCNyzZlb8WbUjn83jhhRf4xje+MaPYSySzjloNK1LElvMDGOwUyzfWHRRpn6d/B2pnsXRj9FaR7++fCCoVaq0WQ0YGhowM+Jd/wdbXx0h+PkO5uQzn5zN46BAAGpMJ/Yb1GDZkYNiwftFm/3gZXHgoNZiHUoMZttg4dq6bQ1UdHKrq4E+nW3DRqMmK9mVbgj/bEkyY3BdHr1HrpCUtIA1jn5GEhAQGxgYobi8mry2P/PZ8jrccB0T55/RAkQKaHpBOsNviHYeZT+bsCb+iooIXX3yR1tZWNBoN/v7+bNmyheDgYLKyskhLS2Pt2rUT599333088sgjkz5DPuHfPNLuW8RuFTN96w5C/RHorBD7jf6izk/0VojMAcPUuvGKomBtbmY4v4CRwgKGCwqxXxIzT51DQtCvT8eQno5+/Xqc/f2nvP92mO3rbbU7KL54iUNVnRyq6qSlbxQQi7hvjfdna4JpxjIP88lMdjcPNk+UgChqL6LX3AvACuMK0gLSSA9IJz0gHX/D7F6H+WLRZunMBlLwbx5p9ywx0C5KO9cfhoajMNoHqCBojRD+qC0Qsn7Kwi4gyjxb6uoZKchnuKiYkeJiHAMi9dAlLAx9ejr69DT0aWk4B9xe7Zm5vN6KolDTMcinNV0cru7kTPNlFAUC3HVsSTCxLcFERqQvri7zP4bxRexWFIWG/gYK20X6Z0lnyUQKaJh72IQDSAtIw9fVdz6afdtIwZ8BKXzLizm122GHts+EAzj/KTQXgWIX5R7CsyAqByLvEou6T/Pkq9jtWM6dY7iwiJGiIuEAhoYAcA4ORr9uHfq0dejXrcM59OZmn87n9e4ZsnC0posj1V2crOtmeMyOVqMmM8qHLfEmcuJNBHvdWpLFzXIrdtsddmr7ainqKKK4o5jSzlKGrOI6hLuHk+KfQqp/Kqn+qQQZgha8FzMdUvBnQArf8mJe7TYPwMVTVx3AJVG3B6O/GPSNvAsiN0876xeuOoCRkhJGiksYKSnB3tcHgMbPD9d1qehT16FPTUEbG4vqBllAC3W9LTY7hQ2X+LSmi6PnumjsHQEgzt+NnHgTOXF+pIR5zdl6vrNht81ho+ZSDSUdJZR2llLaVcrg2CAAAYYAUv1TJ9JAQ9xCFoUDkII/A1L4lhcLandfI1w4Dg3HoeGYqPcD4BMNEdkQvklsxulLB1yZADZSXMxISSkjpaXY2tsBULu54bp2DfqUVFxT1uKalITa9WrJ6MVwvRVFoaFnmE+ru/i0povii5ewORTcdBo2xfhyV6yJzXF++M/iwO9c2O1QHNRfrhfi31lKSUfJxBiASW8iLSBtwR3AHZulI5EsGbzCwOsxSHlMpH52VY07gGNioZeSN8V5ppVC+COyxczf8VW+rp0A5vXoo4BY5H2ktHTCAXSfOCk+Q6NBl5AgnMDatWBc+FmzKpWKKD8jUX5GnsiOZMBsJa++h6M13Ryr7eKjs6J2zspAd3Li/ciJM7E21GvR5fyrVWpivWKJ9Yrlq/FfRVEULgxcoKSjRAwEtxXw14a/AmByNZEakMo6/3WsC1hHhPv8puPeKvIJf4kh7V5k2G0i9//CcbhwEpoKwDYKqETKZ/hGMQ4QtnHKMo/XYuvrY7SsjNHTnzH62WeMnj2LYjYDoAkIwHXNGlzXJOOanIxu1SrUi6QWkKIoVLcPcqy2i2M13ZQ29WF3KHjqncmO8WNLvInsWD+8DTfX3oW43lccQHF7MSWdJZR0ltAzKnpzPjof1gWsm+gBRHjMjQOQIZ0ZWLQCMMdIuxc5tjFoLYGLuXDxpBgAtonUR0yrhAMIzRA9ALeZM3gUqxVzTQ0XD3yMe0cHo2fOTBSCUzk7o1u5El3yalyTVuOavBrnkMURg+4fsXKyvpujNd0cr+2iZ2gMlQrWhHiSE2ciJ06kfao/5+l/MVxvRVFoHGicEP/ijmK6RroA8NZ5TwoBzZYDkII/A4vhhlgIpN13GLYxUfXz4kkxENxcDNZhccw7EkIzhfiHZYBXxJQsoGvttnZ1iV7AmTOMlpVhrqxCGRXOxMnTE93qJFxXJ+OalIguKQmN98w9ivnA4VA429rPpzVdHKvtprxFpH36GrVsjvUjJ96PTdF+eOinLpq+GK+3oii0DLZQ3FlMcUcxRR1FkxzAlQygdf7riPGKQa26+QFtGcOXSO5kNC5iZm/oBsj+npgA1l4OTXnQmAfn/gpn3hbnGv3FeSHj5wesnvRRziYTztu34759OyCWgLTU1TFafpbR8jLM5eX0nDwl6gQBzkFB6JKS0CWuwjUpCd2qVTi5zc2ShNOhVqtIDvEkOcST/7c9lp4hCydquzl2rpvD1Z386XQLahUkh3iyKcaP7BhfkkM85yzz53ZRqVSEuIcQ4h7CgzEPTjiAoo4iMQjcWcKhRjEj293FnRT/FNb5ryPFlEK8TzzO6qmObdbbKJ/wlxbS7iWGwwHdNdCUL2YCN+XD5SZxzNnAsFcChvgcMQkseB24et3w4+xDw5irKjGfrWC04izmikqszc0Tx13Cw9ElJgonkJiILiFhQaqD2h0KZ5r7OF7bw8m6bsqaL+NQwKjVkBHlQ6ybjUc3rybEe37y/meLtqG2CfEv6SihaVBcS1eNK8l+yWIugCmV1X6r0WmmZjXJkM4MLFkB+Byk3cuA/lax8ldTIebao+j6z4uJYCAmf4WkQ3C6ePWJETWEboCtrw9zRSXmygrMlZWMVlROpIWiUuESGYkuIUGMC6xciS4hHiePmRcnmQv6R6zkne/hRJ1wAFdKPkSbjOTEicyfdeHeuGgW59P/THSPdHO66zSlnaWc7jxNbV8tCgoRHhHs+/K+KedLwZ+BZSUA1yDtXl5UV1eTEBkixgGaC8UgcHMRmC+LE7QeEJwqHEBwmvj5c3oBALaennHxr8BcVY25quqqE0DMEBZOIAFtfDy6lSvRmEzzMjCsKAqHC8tpsrlz7FwXhQ2XGLM7MGo1ZEX7kh3rx6YY3zvu6R9gYGyAM11nAMgOnlpYUsbwJZLljtYocvsjxgXC4YDeOmgpEat/tRTDiZdAcYjjPtGwYp0IAa1IAf+kKTWBNL6+GDdvxnjNsqO2S5eE+FdXYa4S25UqoQBO3t7o4uPHnUACuvg4XMLDUd1gIaRbQaVSEezhwvaECL6VFcGwxUZufQ9Hz3Vz7FwXH1eKvP8IXwObYnzJjvFjQ5QPxkVY7vl63F3cpxX62WLx/wckEsnNoVaDX5zY1v692GcZFPWAWoqhpVQUhCt/Vxxz0kLgaliRCkHj5aO9o6aEgjTe3hizNmLM2jixzz40jOVczbgjqMZcU03vb38HVisAKq0WbUwMuoR4tHHx6OJi0cbGzmpIyKDVsGNVADtWBaAoCue7hzgxHvv/Y0kLv8tvRKNWkRLqRVaML5tifFkd7LnoJn7NB1LwJZLlgNZtci9AUaC/RcwJaCmB1lKxHkDhr8bP94Cg5KsOIHANeIZOSQt1MhrQp6aivyZ8oIyNYblwAXN1NZaac5hrahg8dJjLf3x/4hxNQADa2Bh0sbFo4+LQxsbiEhFx2xPGVCoV0SY3ok1ufDMrAovNTmljHydqezhV383PDtXys0O1uOs0bIz2JWu8B3Anhn9uBSn4EslyRKUCzxCxrfpbsc9ug55z0HpajAm0nob8V8EhntZx9RbloQPXQNBa8bNHyBQnoHJxQRcXhy4ubmKfoijYOjux1NZiqa3FfE689uYXTPQG0GhwCQ8TPYLYWLQxMWhjYnAODr5hAbkbodU4TazxC/H0DlnIPd/LqbpuTtb1cKBChH9CvfVkxfiSFe1LZpQPnvrFMVN5tpGCL5FIBE4a8F8ltpSvi302i1gMpu2MCAm1n4G8X4DDJo67ekFgstgCVgtn4B05JRykUqlwDgjAOSAA4zWr3ClWK2MXL2KurcVSV4eltg7z2QoGD3x89b1aLS5RkWijotFGR6ONiQZUKHFxqD4nA+l6fIxaHkgO4oHkoPHwzzCn6ro5Vd/LvjNtvFPYhEoFSSs8yIoWDiA13AutZuHWLZ5NpOBLJJKZ0WhFbH/FNRkfVjN0VopeQEe5mChW8Euwj4njLkZRJygg6epmSgBn1ykfr3J2nniSvxbH8DCW+nrhBOrPY6mvZ6S4mIH9+yfOOafToY2MRBsTjUv0FWcQg3NQ0BdyBCL8YyTaZOTxjRFY7Q7KWy5zsq6H3PoeXjvRwH8fO4/OWU16hA9Z0T5kRfsRH+D2uaUfFitS8CUSyc3hrBtP9bzGCdjGxASxjnKxOHzHWSh7F4pfF8dVavCNHXcEieLVP1HUC5omlVNtMOCaLIrBXYt9cBBLfT2NJ0/iNTyMpf48wwWF9P/f1Zx1lVaLS3g4LhERaCMjcImIwCUiEm1E+A0nkTk7qUkN8yY1zJvvbItl0GylsOESp+p7OFXfw/Mf1QA1+BhcyIjyEWMA0XdW+qcUfIlEcvtoXESmT+BqWLtL7HM44HKjEP8rW3MRVFwdvEXvMx5GShTlo/1Xgl8CuEwvok5ubqIstE6H/zX56PaBgfGeQB1jFy4y1tCAubqKwYMHRTuuNNPfH5fICLQRkbhERk44BI2//5RegZvOmW0r/dm2Uqx/29Fv5lS9ePrPre/hw3IxLyHE25WNUb5kRvuSEemDn5t2Nv6jc4IUfIlEMjeo1eAdIbaVD1zdP3pZhIQ6K6HzLHRUQMmvr1YNRSXGAfxXigqipnjhBHyiwGn6ejNO7u7oU9aiT1k7ab9jbAxrUxOWhoYJR2C5eIH+ffsmlpkEUOl0uISFiZ5BeDguEeFow8NxDgtD4yUmqgV46HgoNZiHUoMn0j9z63vJre/hr2fbebdYlKiI83eb6AGkR3jj4Tr3NXK+KFLwJRLJ/OLqOb4OwNV8fhx26LsonEBX1VWHUP0hMF4MQO0sJo2Z4vFV+YKySZSS8I6c0RGoXVxEbD86etJ+RVGw9/RgabjA2IULjF28yNjFi1hqahg8fBjs9olznTw8cA4Pm3AALmFhuISFExEWSnRmON/IDMfuUKho7SfvfC9553t4t7iJ3+RdRD0+AJwR5cvGaB/WhXkvyKLvV5CCL5FIFh61k3iC94ma3BuwjkJPLXTVQHe1eG37DL++i1AxPj6g1ghH4BcHvuMTznxjwTdm2oFiEAO2Gj8/NH5+GNanTzqmWK2MtbSIHkFjI2ONFxm72MhwUTG2/5tc38bJywuX0FCcw0IJCg3ja2GhPJ4agvJAGmcHILfhEnn1PbxxsoFfHT+Ps5OKtaFeZEb5kBnly5oQz3mt/yMFXyKRLF6cXa+mfV5DzdnTxPuoofucGCzuPidCQ9X7r5aQYHyuge81DuDKq8Fv2sFiGM8ciohAGxEx5ZhjdJSxpmbGmhqxNjUx1tjEWGMjI8UlDOzbP+lcT6ORL4eG8HehYaiCVtDi6kW5w42TPWPsvdDDK4fr0Ls4kRHpw+Y4P7Jj/Aj3ndvKpFLwJRLJHYeicYWgBDH561qsZrh0XvQKumvFa885sbjMxBgBoPMQlUR9Y8E3WvQQfKJFeGiGXgGA2tUVXVwsurjYKcccZjPWlhbGmpqxNjeNO4YmLNXVjB05grvVShaQBaDRYPX1p9vdl7pyd8qc3Dmo90YJXEHs2jj+JiOWdeGzv0CNFHyJRLJ0cNZdnTx2LQ4HDLSMO4B68dpbJ2oKlb1zzYkqMXvYJ2rcCUSJukI+UaK0xAxjBQBqnW7a8QIAxW7H1tHBWHMzY83NWJvEq1tLCyHN5Wzu77968j6o9w1HOfnRrFcflYIvkUiWPmq1EGzPUIjeNvmYZRB6z0Nv/eSt/D2wDFw9T+UEXmGiF3DFCXhHiu1znIHKyQnnFStwXrECw4YNU47bBwdF76C5GXNjM97u7nNSaloKvkQiWd5o3URo6PrwkKLAcI8IEfWeF6+XGsTPTQUwdjWtE5WTEH3vyPFU1EixBrF3pHASNwgTgZhf4JSQgC4hAfc5MPEKUvAlEolkOlQqMPqJLfS6p3JFgeFu4QCuOIFL5+HSBVF91NI/+Xy3IPAKn7x5R4BnGBhNMw4gzzZS8CUSieRmUamEUBtN0zuD0T4h/lccQt9FsTUcg8G2yedrXEXvwCtc9AY8wyAsY3L9ollCCr5EIpHMJioV6L3FFjyNaFvNYiH6vgvQ1ygcweVG8XNTvhg3MAbAM+dmvWlS8CUSiWQ+cdaBX6zYrudK70A9N7NxpeBLJBLJYuFK72COmNM5vbW1tWzbto233357yrG8vDweeughHnnkEV599dW5bIZEIpFImEPBHxkZ4T/+4z/IyMiY9vh//ud/snfvXv73f/+X3Nxc6uvr56opEolEImEOBd/FxYXXX38dk8k05VhzczMeHh4EBgaiVqvZvHkz+fn5c9UUiUQikTDps77LAAAHE0lEQVSHMXyNRoNGM/3Hd3d34+19NU7l7e1Nc3PztOdWV1ff0t83m823/N47GWn38kLavby4XbsX/aBtwjWr2twM1dXVt/zeOxlp9/JC2r28+KJ2l5aWTrt//goxX4PJZKKnp2fi987OzmlDPxKJRCKZPRZE8IODgxkaGqKlpQWbzcbRo0fZuHHj579RIpFIJLeMSlEUZS4+uKKighdffJHW1lY0Gg3+/v5s2bKF4OBgtm/fTnFxMS+//DIAO3bs4Fvf+taUz5ipWyKRSCSSG5OaOnWW75wJvkQikUgWFwsS0pFIJBLJ/CMFXyKRSJYJiz4t82Z5/vnnKSsrQ6VS8cMf/pDVq1cvdJPmlNraWnbv3s3jjz/Orl27aG9v5/vf/z52ux0/Pz9++tOf4uListDNnHVeeuklSktLsdlsPPnkkyQlJS15u0dHR9mzZw+9vb1YLBZ2795NfHz8krf7Cmazmfvuu4/du3eTkZGx5O0uLCzk6aefJiYmBoDY2Fj+8R//8bbsXlJP+EVFRTQ2NvLee+/x3HPP8dxzzy10k+aU6cpX/OIXv+BrX/sa77zzDmFhYbz//vsL2MK5oaCggLq6Ot577z3eeOMNnn/++WVh99GjR0lMTOTtt9/mlVde4YUXXlgWdl/hl7/8JR4eHsDyuM8B0tPTeeutt3jrrbf4t3/7t9u2e0kJfn5+Ptu2ifUqo6Ki6O/vZ2ho6HPedecyXfmKwsJCtm7dCkBOTs6SLFmRlpbGz3/+cwDc3d0ZHR1dFnbfe++9PPHEEwC0t7fj7++/LOwGOH/+PPX19dx1113A8rjPp+N27V5Sgt/T04OXl9fE797e3nR3dy9gi+YWjUaDTqebtG90dHSii+fj47Mk7XdyckKv1wPw/vvvk52dvSzsvsKjjz7KM888ww9/+MNlY/eLL77Inj17Jn5fLnbX19fzz//8z3z1q18lNzf3tu1ecjH8a1nuGadL3f7Dhw/z/vvv8+abb7Jjx46J/Uvd7nfffZfq6mq+973vTbJ1qdr9wQcfsGbNGkJCQqY9vlTtDg8P56mnnmLnzp00Nzfz2GOPYbfbJ47fit1LSvCvL9nQ1dWFn5/fArZo/tHr9ZjNZnQ63ZIuWXHy5El+9atf8cYbb+Dm5rYs7K6oqMDHx4fAwEASEhKw2+0YDIYlb/exY8dobm7m2LFjdHR04OLisiyut7+/P/feey8AoaGh+Pr6cvbs2duye0mFdDZu3Mgnn3wCQGVlJSaTCaPRuMCtml8yMzMn/gcHDx5k06ZNC9yi2WdwcJCXXnqJ1157DU9PT2B52F1SUsKbb74JiPDlyMjIsrD7lVde4U9/+hN/+MMfePjhh9m9e/eysHvfvn38z//8DyAqDPf29vLggw/elt1Lbqbtyy+/TElJCSqVin//938nPj5+oZs0Z0xXvuLll19mz549WCwWgoKC+MlPfoKzs/NCN3VWee+999i7dy8RERET+1544QV+9KMfLWm7zWYzzz77LO3t7ZjNZp566ikSExP513/91yVt97Xs3buXFStWkJWVteTtHhoa4plnnmFgYACr1cpTTz1FQkLCbdm95ARfIpFIJNOzpEI6EolEIpkZKfgSiUSyTJCCL5FIJMsEKfgSiUSyTJCCL5FIJMuEJTXxSiK5FVpaWrj//vtJTEyctH/v3r0Tef63wt69e/Hy8mLXrl2320SJZFaQgi+RABEREbz11lsL3QyJZE6Rgi+RzMCePXvQ6/U0NDTQ19fHT37yE1auXMlvf/tbPvroIwC2bt3KP/3TP9Ha2sqePXuw2+0EBQXx4osvAmK9gieffJKLFy/y7LPPkp2dvZAmSZY5MoYvkdwAm83Gb37zG55++mleffVVmpub+ctf/sLvf/97fv/733PgwAGampr4r//6Lx5//HHeeecdTCYTFRUVAFy+fJnXXnuNH/3oR7z77rsLbI1kuSOf8CUS4MKFC3z961+f+P1K2YbMzEwA1qxZw8svv0x1dTXJycloNOKrk5KSQk1NDVVVVTz77LMAfP/73wfgxIkTpKSkAKIQ1uDg4LzZI5FMhxR8iYTpY/h79uzB4XBM/K5SqVCpVJPK0lqtVtRqNU5OTtOWq73iGCSSxYAM6UgkN6C0tBSAzz77jKioKBISEjhz5gw2mw2bzUZZWRkJCQkkJiZSUFAAwM9//nPy8vIWstkSybTIxw+JhKkhHQCdTodGo+HJJ5+kvb2dn/70pwQHB/PII4+wa9cuFEXh4YcfZsWKFXz729/mBz/4Ae+88w6BgYE89dRTE85CIlksyGqZEskM7Nmzh7vvvpucnJyFbopEMivIkI5EIpEsE+QTvkQikSwT5BO+RCKRLBOk4EskEskyQQq+RCKRLBOk4EskEskyQQq+RCKRLBOk4EskEsky4f8DeJ8PcB3aBMcAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.pylabtools import figsize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "epochs = np.arange(0, 50, 1)\n",
        "\n",
        "plt.plot(epochs, loss_all_train_adam, label='Train Loss Adam')\n",
        "plt.plot(epochs, loss_all_test_adam, label='Test Loss Adam')\n",
        "plt.plot(epochs, loss_all_train_nosadam, label='Train Loss NosAdam')\n",
        "plt.plot(epochs, loss_all_test_nosadam, label='Test Loss NosAdam')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig('cifar.pdf')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Comparing Optimizers on CIFAR10.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a31065c2cb285fc89af45a6e0e00b20f2f53e470cc5659f0bf6d768d5279787d"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 ('knvenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
