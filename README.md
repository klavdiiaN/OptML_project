# Optimization for Machine Learning

This repository containes code and files for the project: "The impact of memory in optimization: how can a long-term memory improve the performance of Adam". The structure is as follows:
- Jupyter notebook [NosAdam_MNIST.ipynb](NosAdam_MNIST): search for the best parameters for NosAdam optimizer for MLP and CNN models using MNIST dataset,
- Jupyter notebook [Adam_MNIST_all_plots.ipynb](Adam_MNIST_all_plots): search for the best parameters for Adam optimizer for MLP and CNN models using MNIST dataset, the plots of convergence used in the report and the bootstrapping for both optimizers on MNIST,
- Jupter notebook [Adam_NosAdam_CNN_CIFAR10.ipynb] 'Adam_NosAdam_CNN_CIFAR10': search for the best parameters for both optimizers for CNN model using CIFAR10 dataset and corresponding plots of convergence,
- Folder [mnist_data] 'mnist_data': MNIST dataset of 50k train and 10k test samples,
- 
